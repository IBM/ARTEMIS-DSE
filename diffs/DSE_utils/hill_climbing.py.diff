--- ./Project_FARSI_orig/DSE_utils/hill_climbing.py
+++ ./Project_FARSI/DSE_utils/hill_climbing.py
@@ -20,15 +20,18 @@
 from visualization_utils import vis_hardware, vis_stats, plot
 from visualization_utils import vis_sim
 #from data_collection.FB_private.verification_utils.common import *
+from pygmo import hypervolume
 import dill
 import pickle
 import importlib
 import gc
 import difflib
+import sys
+import math
 #from pygmo import *
 #from pygmo.util import *
 import psutil
-
+from abc import ABC, abstractmethod
 
 class Counters():
     def __init__(self):
@@ -70,12 +73,16 @@
 # current bottleneck) as two main exploration move.
 # ------------------------------
 class HillClimbing:
-    def __init__(self, database, result_dir):
+    def __init__(self, farsi_start_time:float, database:DataBase, result_dir:str, viz_dir:str):
+        self.FARSI_start_time = farsi_start_time
+        self.last_move_kernel = None
 
         # parameters (to configure)
+        self.task_names_specialized_for = set() # hash to record all the task names for which we have used moves: split_swap or swap
         self.counters = Counters()
         self.found_any_improvement = False
         self.result_dir = result_dir
+        self.viz_dir = viz_dir
         self.fitted_budget_ctr = 0  # counting the number of times that we were able to find a design to fit the budget. Used to terminate the search
         self.name_ctr = 0
         self.DES_STAG_THRESHOLD = config.DES_STAG_THRESHOLD   # Acceptable iterations count without improvement before termination.
@@ -135,6 +142,8 @@
         self.seen_SOC_design_codes = []  # config code of all the designs seen so far (this is mainly for debugging, concretely
                                      # simulation validation
 
+        # DYN_SCHEDULING_INSTEAD_OF_MAPPING = 1: dict of nx object to tuple of ex_dp, sim_dp
+        # DYN_SCHEDULING_INSTEAD_OF_MAPPING = 0: dict of string to tuple of ex_dp, sim_dp
         self.cached_SOC_sim = {} # cache of designs simulated already. index is a unique code base on allocation and mapping
 
         self.move_s_krnel_selection = config.move_s_krnel_selection
@@ -148,6 +157,69 @@
         self.total_iteration_ctr = 0
         self.moos_tree = moosTreeModel(config.budgetted_metrics)  # only used for moos heuristic
         self.ctr_l = 0
+        self.reverted_last_itr = False
+
+    def add_to_krnels_not_to_consider(self, ex_dp, task_name:str):
+        # for dynamic scheduler as mapper mode, also choose other kernels that are mappable to the same IP into the list
+        # print(f"Adding {task_name}")
+        if config.CLUSTER_KRNLS_NOT_TO_CONSIDER:
+            hw_graph = ex_dp.get_hardware_graph()
+            task = hw_graph.get_task_graph().get_task_by_name(task_name)
+            task_s_blocks = hw_graph.get_blocks_of_task(task)
+            task_specialized_to = None
+            task_s_mems = set(hw_graph.get_mems_of_task(task))
+            for b in task_s_blocks:
+                if b.subtype == "ip":
+                    task_specialized_to = b.instance_type
+                    break
+            if task_specialized_to == None:
+                if task_name not in self.krnels_not_to_consider:
+                    self.krnels_not_to_consider.append(task_name)
+                return
+            try:
+                all_tasks = self.database.pe_to_mappable_task_map[task_specialized_to]
+            except:
+                print(f"{task_specialized_to} not found in pe_to_mappable_task_map")
+                pprint(self.database.pe_to_mappable_task_map)
+                exit(1)
+            for other_task_name in all_tasks:
+                other_task = hw_graph.get_task_graph().get_task_by_name(other_task_name)
+                # if there are other tasks that read/write from/to the same memory as this task, add them to the "not to consider" list
+                if set(hw_graph.get_mems_of_task(other_task)) == task_s_mems and other_task_name not in self.krnels_not_to_consider:
+                    self.krnels_not_to_consider.append(other_task_name)
+        else:
+            self.krnels_not_to_consider.append(task_name)
+
+    def remove_from_krnels_not_to_consider(self, ex_dp, task_name:str):
+        # for dynamic scheduler as mapper mode, also choose other kernels that are mappable to the same IP into the list
+        # print(f"Removing {task_name}")
+        if config.CLUSTER_KRNLS_NOT_TO_CONSIDER:
+            hw_graph = ex_dp.get_hardware_graph()
+            task = hw_graph.get_task_graph().get_task_by_name(task_name)
+            task_s_blocks = hw_graph.get_blocks_of_task(task)
+            task_specialized_to = None
+            # task_s_mems = set(hw_graph.get_mems_of_task(task))
+            for b in task_s_blocks:
+                if b.subtype == "ip":
+                    task_specialized_to = b.instance_type
+                    break
+            if task_specialized_to == None:
+                self.krnels_not_to_consider.remove(task_name)
+                return
+            try:
+                all_tasks = self.database.pe_to_mappable_task_map[task_specialized_to]
+            except:
+                print(f"{task_specialized_to} not found in pe_to_mappable_task_map")
+                pprint(self.database.pe_to_mappable_task_map)
+                exit(1)
+            for other_task_name in all_tasks:
+                other_task = hw_graph.get_task_graph().get_task_by_name(other_task_name)
+                # if set(hw_graph.get_mems_of_task(other_task)) == task_s_mems and other_task_name in self.krnels_not_to_consider:
+                # if there are other task mappable to the same IP as this task, remove them to the "not to consider" list
+                if other_task_name in self.krnels_not_to_consider:
+                    self.krnels_not_to_consider.remove(other_task_name)
+        else:
+            self.krnels_not_to_consider.remove(task_name)
 
     def get_total_iteration_cnt(self):
         return self.total_iteration_cnt
@@ -235,6 +307,9 @@
     def gen_one_neigh(self, des_tup):
         ex_dp, sim_dp = des_tup
 
+        # else:
+        #     ex_dp.get_hardware_graph().prune_blocks_with_no_tasks(["gpp"])
+
         # Copy to avoid modifying the current designs.
         #new_ex_dp_pre_mod = copy.deepcopy(ex_dp)  # getting a copy before modifying
         #new_sim_dp_pre_mod = copy.deepcopy(sim_dp) # getting a copy before modifying
@@ -247,6 +322,13 @@
         #new_sim_dp = copy.deepcopy(sim_dp)
         new_des_tup = (new_ex_dp, sim_dp)
 
+
+        # new_des_tup = (copy.deepcopy(ex_dp), copy.deepcopy(sim_dp))
+        # new_ex_dp = new_des_tup[0]
+
+        if not config.CONSTRAIN_TOPOLOGY and config.DYN_SCHEDULING_INSTEAD_OF_MAPPING:
+            new_ex_dp.get_hardware_graph().prune_blocks_with_no_tasks()
+
         # ------------------------
         # select (generate) a move
         # ------------------------
@@ -255,6 +337,7 @@
         # 2. for block identification/comparison of the move and the copied design
         safety_chk_passed = False
         # iterate and continuously generate moves, until one passes some sanity check
+            
         while not safety_chk_passed:
             move_to_try, total_transformation_cnt = self.sel_moves(new_des_tup, "dist_rank")
             safety_chk_passed = move_to_try.safety_check(new_ex_dp)
@@ -270,7 +353,21 @@
             self.dh.unload_read_mem(new_des_tup[0])    # unload read memories
             move_to_try.validity_check()  # call after unload rad mems, because we need to check the scenarios where
                                           # task is unloaded from the mem, but was decided to be migrated/swapped
-            new_ex_dp_res, succeeded = self.dh.apply_move(new_des_tup, move_to_try)
+            new_ex_dp_res, _ = self.dh.apply_move(new_des_tup, move_to_try)
+            self.last_move_kernel = move_to_try.get_kernel_ref()
+            if config.DYN_SCHEDULING_INSTEAD_OF_MAPPING:
+                for b in new_ex_dp_res.hardware_graph.blocks:
+                    b.reset_area_lists()
+            if config.DEBUG_SANITY and not config.USE_CUST_SCHED_POLICIES:
+                for b in new_ex_dp_res.hardware_graph.blocks:
+                    if b.type == "pe":
+                        # verify that pe can run each task mapped to it
+                        block_generic_instance_name = b.instance_name.split('_pe')[0]
+                        for task in b.get_tasks_of_block():
+                            assert task.name in self.database.task_to_mappable_pe_map, f"{self.database.task_to_mappable_pe_map}"
+                            if block_generic_instance_name not in self.database.task_to_mappable_pe_map[task.name]:
+                                print(f"{block_generic_instance_name} cannot run task {task.name}, self.database.task_to_mappable_pe_map = \n{self.database.task_to_mappable_pe_map}")
+                                assert False
             move_to_try.set_before_after_designs(new_des_tup[0], new_ex_dp_res)
             new_ex_dp_res.sanity_check()  # sanity check
             move_to_try.sanity_check()
@@ -350,7 +447,7 @@
     # check if there is another task (on the block that can run in parallel with the task of interest
     def check_if_task_can_run_with_any_other_task_in_parallel(self, sim_dp, task, block):
         parallelism_type = []
-        if task.get_name() in ["souurce", "siink", "dummy_last"]:
+        if task.is_task_dummy():
             return False, parallelism_type
         if block.type == "pe":
             task_dir = "loop_back"
@@ -449,7 +546,7 @@
                 else:
                     block_pairs_sorted.append((blck_2, blck_1))
 
-            distance = len(sim_dp.get_dp_rep().get_hardware_graph().get_path_between_two_vertecies(blck_1, blck_2))
+            distance = len(sim_dp.get_dp_rep().get_hardware_graph().get_path_between_two_vertices(blck_1, blck_2))
             num_tasks_to_move = min(len(blck_1.get_tasks_of_block()), len(blck_2.get_tasks_of_block()))
 
             cleanup_ease_list.append(distance + num_tasks_to_move)
@@ -545,38 +642,41 @@
             selected_metric_to_sort = 'peak_work_rate'
         elif selected_metric == "power":
             #selected_metric_to_sort = 'work_over_energy'
-            selected_metric_to_sort = 'one_over_power'
+            # selected_metric_to_sort = 'one_over_power'
+            selected_metric_to_sort = 'one_over_total_power'
         elif selected_metric == "area":
             selected_metric_to_sort = 'one_over_area'
         else:
             print("selected_selected_metric: " + selected_metric + " is not defined")
         return selected_metric_to_sort
 
-    def select_block_to_migrate_to(self, ex_dp, sim_dp, hot_blck_synced, selected_metric, sorted_metric_dir, selected_krnl):
+    def select_block_to_migrate_to(self, ex_dp:ExDesignPoint, sim_dp, hot_blck_synced:Block, selected_metric, sorted_metric_dir, selected_krnl:Kernel, force=False):
+        # print(f"!! force={force}, select_block_to_migrate_to hot_blck_synced = {hot_blck_synced.instance_name}, selected_metric = {selected_metric}, sorted_metric_dir = {sorted_metric_dir}, selected_krnl = {selected_krnl.task_name}")
         # get initial information
         locality_type = []
         parallelism_type =[]
         task = ex_dp.get_hardware_graph().get_task_graph().get_task_by_name(selected_krnl.get_task_name())
         selected_metric = list(sorted_metric_dir.keys())[-1]
+        block_metric_attr = self.get_block_attr(selected_metric) # metric to pay attention to
         selected_dir = sorted_metric_dir[selected_metric]
         # find blocks equal or immeidately better
         equal_imm_blocks_present_for_migration = self.dh.get_equal_immediate_blocks_present(ex_dp, hot_blck_synced,
                                                                 selected_metric, selected_dir, [task])
 
+        # print(f"## equal_imm_blocks_present_for_migration = {[b.instance_name for b in equal_imm_blocks_present_for_migration]}")
 
         # does parallelism exist in the current occupying block
         current_block_parallelism_exist, parallelism_type = self.check_if_task_can_run_with_any_other_task_in_parallel(sim_dp,
                                                                                                      task,
                                                                                                      hot_blck_synced)
         inequality_dir = selected_dir*-1
-        results_block = [] # results
+        results_block:List[Block] = [] # results
 
         task_s_blocks = ex_dp.get_hardware_graph().get_blocks_of_task(task)
         if len(task_s_blocks) == 0:
             print("a task must have at lease three blocks")
             exit(0)
 
-
         remove_list = []  # list of blocks to remove from equal_imm_blocks_present_for_migration
         # improve locality by only allowing migration to the PE/MEM close by
         if hot_blck_synced.type == "mem":
@@ -589,9 +689,11 @@
                 if el not in potential_mems:
                     remove_list.append(el)
                     locality_type = ["spatial_locality"]
-            for el in remove_list:
-                equal_imm_blocks_present_for_migration.remove(el)
-        elif hot_blck_synced.type == "pe":
+            if not config.CONSTRAIN_TOPOLOGY:
+                for el in remove_list:
+                    # print(f"## removed block from potential dests: {el.instance_name}")
+                    equal_imm_blocks_present_for_migration.remove(el)
+        elif not config.CONSTRAIN_TOPOLOGY and hot_blck_synced.type == "pe":
             # only keep memories that are connected to the IC neighbour of the task's pe
             # This is to make sure that we keep data local (to the router), instead of migrating to somewhere far
             task_s_mems = [blk for blk in task_s_blocks if blk.type == "mem"] # get task's pe
@@ -604,7 +706,10 @@
                     remove_list.append(el)
                     locality_type = ["spatial_locality"]
             for el in remove_list:
+                # print(f"## removed block from potential dests: {el.instance_name}")
                 equal_imm_blocks_present_for_migration.remove(el)
+            # for el in remove_list:
+            #     equal_imm_blocks_present_for_migration.remove(el)
 
         # iterate through the blocks and find the best one
         for block_to_migrate_to in equal_imm_blocks_present_for_migration:
@@ -612,7 +717,6 @@
             if block_to_migrate_to == hot_blck_synced:
                 continue
 
-            block_metric_attr = self.get_block_attr(selected_metric) # metric to pay attention to
             # iterate and found blocks that are at least as good as the current block
             if getattr(block_to_migrate_to, block_metric_attr) == getattr(hot_blck_synced, block_metric_attr):
                 # blocks have similar attr value
@@ -620,8 +724,8 @@
                     (selected_metric == "latency" and selected_dir == 1) or (selected_metric == "area"):
                     # if we want to slow down (reduce latency, improve power), look for parallel task on the other block
                     block_to_mig_to_parallelism_exist, parallelism_type = self.check_if_task_can_run_with_any_other_task_in_parallel(sim_dp,
-                                                                                                               task,
-                                                                                                               block_to_migrate_to)
+                                                                                                                task,
+                                                                                                                block_to_migrate_to)
                     if (selected_metric == "area" and selected_dir == -1):
                         # no parallelism possibly allows for theo the other memory to shrink
                         if not block_to_mig_to_parallelism_exist:
@@ -633,14 +737,15 @@
                             parallelism_type = ["serialism"]
                 else:
                     # if we want to accelerate (improve latency, get more power), look for parallel task on the same block
-                    if current_block_parallelism_exist:
+                    if current_block_parallelism_exist or force:
                         results_block.append(block_to_migrate_to)
+                    block_to_mig_to_parallelism_exist = current_block_parallelism_exist
             elif inequality_dir*getattr(block_to_migrate_to, block_metric_attr) > inequality_dir*getattr(hot_blck_synced, block_metric_attr):
                 results_block.append(block_to_migrate_to)
-                break
 
         # if no block found, just load the results_block with current block
-        if len(results_block) == 0:
+        # or if migrating from the hot block will not leave any tasks mapped on it, for mesh-constrained mode
+        if len(results_block) == 0: #   or (config.CONSTRAIN_TOPOLOGY and len(hot_blck_synced.get_tasks_of_block())) == 1:
             results_block = [hot_blck_synced]
             found_block_to_mig_to = False
         else:
@@ -648,15 +753,40 @@
 
         # pick at random to try random scenarios. At the moment, only equal and immeidately better blocks are considered
         random.seed(datetime.now().microsecond)
-        result_block = random.choice(results_block)
+        # For migrate_swap move only: if force is enabled, migrate tasks to a GPP so that the current block can be swapped out for an IP.
+        if force and found_block_to_mig_to:
+            found_block_to_mig_to = False
+            for b in results_block:
+                if b.subtype == "gpp":
+                    result_block = b
+                    found_block_to_mig_to = True
+                    break
+        else:
+            result_block = random.choice(results_block)
+            # print(f"Potential blocks: {[b.instance_name for b in results_block]}")
+            # result_block = self.sel_blk_w_most_potential_idle_time(results_block)
+            # print(f"Result block: {result_block.instance_name}")
+        if found_block_to_mig_to == False:
+            result_block = hot_blck_synced
 
         selection_mode = "batch"
         if found_block_to_mig_to:
             if getattr(result_block, block_metric_attr) == getattr(hot_blck_synced, block_metric_attr):
+                # if block_to_mig_to_parallelism_exist:
+                #     selection_mode = "batch"
+                # elif force:
+                #     selection_mode = "inv-single"
                 selection_mode = "batch"
+                if force:
+                    selection_mode = "mappable_to_same_ip"
+                # selection_mode = random.choice(["mappable_to_same_ip", "batch"])
+                # print(f"## block_to_mig_to_parallelism_exist = {block_to_mig_to_parallelism_exist}, selection_mode = {selection_mode}")
             else:
                 selection_mode = "single"
+                # if force:
+                #     selection_mode = "mappable_to_same_ip"
 
+        # print(f"!! found_block_to_mig_to = {found_block_to_mig_to}, result_block = {result_block.instance_name}, task = {task.name}, selection_mode = {selection_mode}")
 
         return result_block, found_block_to_mig_to, selection_mode, parallelism_type, locality_type
 
@@ -709,8 +839,10 @@
         else:
             return False
 
-    def get_feasible_transformations(self, ex_dp, sim_dp, hot_blck_synced, selected_metric, selected_krnl, sorted_metric_dir):
-
+    def get_feasible_transformations(self, ex_dp, sim_dp, hot_blck_synced, selected_metric, selected_krnl:Kernel, sorted_metric_dir, tasks):
+        selection_mode = None
+        # print(f"## tasks = {[t.name for t in tasks]}")
+        # print(f"## hot task = {selected_krnl.task_name}, hot_blck_synced = {hot_blck_synced.instance_name}")
         # if this knob is set, we randomly pick a transformation
         # THis is to illustrate the architectural awareness of FARSI a
         if config.transformation_selection_mode == "random":
@@ -718,24 +850,30 @@
             return all_transformations
 
         # pick a transformation smartly
-        imm_block = self.dh.get_immediate_block_multi_metric(hot_blck_synced, selected_metric, sorted_metric_dir,  hot_blck_synced.get_tasks_of_block())
+        if config.DYN_SCHEDULING_INSTEAD_OF_MAPPING:
+            tasks = [selected_krnl.get_task()]
+        # imm_block = self.dh.get_immediate_block_multi_metric(hot_blck_synced, selected_metric, sorted_metric_dir, selected_krnl, tasks)
         task = ex_dp.get_hardware_graph().get_task_graph().get_task_by_name(selected_krnl.get_task_name())
         feasible_transformations = set(config.metric_trans_dict[selected_metric])
+        # print(f"## imm_block = {imm_block.instance_name} (type = {imm_block.type})")
+        # print(f"## feasible_transformations = {feasible_transformations}")
+        # print(f"@@ sorted_metric_dir = {sorted_metric_dir}")
 
         # find the block that is at least as good as the block (for migration)
         # if can't find any, we return the same block
         selected_metric = list(sorted_metric_dir.keys())[-1]
         selected_dir = sorted_metric_dir[selected_metric]
+        # print(f"## selected_metric = {selected_metric}, selected_dir = {selected_dir}")
 
-        equal_imm_block_present_for_migration, found_blck_to_mig_to, selection_mode, parallelism_type, locality_type = self.select_block_to_migrate_to(ex_dp, sim_dp, hot_blck_synced,
-                                                                selected_metric, sorted_metric_dir, selected_krnl)
+        # print(f"## equal_imm_block_present_for_migration = {equal_imm_block_present_for_migration.instance_name}, found_blck_to_mig_to = {found_blck_to_mig_to}")
 
         hot_block_type = hot_blck_synced.type
         hot_block_subtype = hot_blck_synced.subtype
 
         parallelism_exist, parallelism_type = self.check_if_task_can_run_with_any_other_task_in_parallel(sim_dp, task, hot_blck_synced)
+        # print(f"## parallelism_exist = {parallelism_exist}, parallelism_type = {parallelism_type}")
         other_block_parallelism_exist = False
-        all_transformations = config.metric_trans_dict[selected_metric]
+        all_transformations = set(config.metric_trans_dict[selected_metric])
         can_improve_locality = self.can_improve_locality(ex_dp, hot_blck_synced, task)
         can_improve_routing = self.can_improve_routing(ex_dp, sim_dp, hot_blck_synced, task)
 
@@ -743,80 +881,151 @@
         # ------------------------
         # based on parallelism, generate feasible transformations
         # ------------------------
+        migrant_sel_mode = "regular"
         if parallelism_exist:
            if selected_metric == "latency":
                if selected_dir == -1:
                     if hot_block_type == "pe":
-                        feasible_transformations = ["migrate", "split"]  # only for PE since we wont to be low cost, for IC/MEM cost does not increase if you customize
+                        feasible_transformations = set(["migrate", "split"])  # only for PE since we wont to be low cost, for IC/MEM cost does not increase if you customize
+                        # since we can't split in constrained toplogy mode, the next best thing is to migrate_swap
+                        if config.CONSTRAIN_TOPOLOGY:
+                            feasible_transformations.add("migrate_swap")
                     else:
                         if hot_block_type == "ic":
                             mem_neighs = [el for el in hot_blck_synced.get_neighs() if el.type == "mem"]
                             pe_neighs = [el for el in hot_blck_synced.get_neighs() if el.type == "pe"]
                             if len(mem_neighs) <= 1 or len(pe_neighs)  <= 1 or not bus_has_pe_mem_topology_for_split:
-                                feasible_transformations = ["swap", "split_swap"]  # ", "swap", "split_swap"]
+                                feasible_transformations = set(["swap", "split_swap"])  # ", "swap", "split_swap"]
                             else:
-                                feasible_transformations = ["migrate", "split"]  # ", "swap", "split_swap"]
+                                feasible_transformations = set(["migrate", "split"])  # ", "swap", "split_swap"]
                         else:
-                            feasible_transformations = ["migrate", "split"] #", "swap", "split_swap"]
+                            feasible_transformations = set(["migrate", "split"]) #", "swap", "split_swap"]
                else:
                     # we can do better by comparing the advantage disadvantage of migrating
                     # (Advantage: slowing down by serialization, and disadvantage: accelerating by parallelization)
-                   feasible_transformations = ["swap"]
+                   feasible_transformations = set(["swap"])
            if selected_metric == "power":
                if selected_dir == -1:
                    # we can do better by comparing the advantage disadvantage of migrating
                    # (Advantage: slowing down by serialization, and disadvantage: accelerating by parallelization)
-                   feasible_transformations = ["swap", "split_swap"]
+                   feasible_transformations = set(["swap", "split_swap"])
                else:
                    feasible_transformations = all_transformations
            if selected_metric == "area":
                if selected_dir == -1:
                    if hot_block_subtype == "pe":
-                       feasible_transformations = ["migrate", "swap"]
+                       feasible_transformations = set(["migrate", "swap"])
                    else:
-                       feasible_transformations = ["migrate", "swap", "split_swap"]
+                       feasible_transformations = set(["migrate", "swap", "split_swap"])
                else:
                    feasible_transformations = all_transformations
         elif not parallelism_exist:
            if selected_metric == "latency":
                if selected_dir == -1:
-                   feasible_transformations = ["swap", "split_swap"]
+                    feasible_transformations = set(["swap", "split_swap"])
+                    feasible_transformations.add("migrate") # even if this task can't run faster in parallel with others, it could benefit from migrating to an accel
                else:
-                   feasible_transformations = ["swap", "migrate"]
+                   feasible_transformations = set(["swap", "migrate"])
            if selected_metric == "power":
                if selected_dir == -1:
-                   feasible_transformations = ["migrate", "swap", "split_swap"]
+                   feasible_transformations = set(["migrate", "swap", "split_swap"])
            if selected_metric == "area":
                if selected_dir == -1:
-                    feasible_transformations = ["migrate", "swap","split_swap"]
+                    feasible_transformations = set(["migrate", "swap","split_swap"])
                else:
-                   feasible_transformations = ["migrate", "swap", "split"]
+                   feasible_transformations = set(["migrate", "swap", "split"])
+        else:
+            raise NotImplementedError
+        # print(f"## 1 feasible_transformations = {feasible_transformations}")
 
+        revert_block = False
+        if config.DYN_SCHEDULING_INSTEAD_OF_MAPPING and config.CONSTRAIN_TOPOLOGY:
+            tasks = [selected_krnl.get_task()]
+            # if an existing IP that could run the hot task if sitting idle, it means that the scheduler cannot make use of yet another one,
+            # so, we will reverse this swap move to swap that idle IP with a GPP
+            for b in ex_dp.get_hardware_graph().get_blocks():
+                if len(b.get_tasks_of_block()) == 0 and b.type == "pe" and b.subtype != "gpp" and b.instance_type in self.database.task_to_mappable_pe_map[selected_krnl.get_task_name()]:
+                    # print(f"@@ reverting block {b.instance_name} to GPP")
+                    revert_block = True
+                    hot_blck_synced = b
+                    break
+        if revert_block:
+            feasible_transformations = set(["swap"])
+            selected_metric = "latency"
+            selected_dir = 1
+            imm_block = self.dh.get_immediate_block_fast(hot_blck_synced, selected_metric, selected_dir, tasks)
+            # print(f"@@ reverting block imm_block = {imm_block.instance_name}, hot_blck_synced = {hot_blck_synced.instance_name}, tasks = {[t.name for t in tasks]}")
+
+        # migrate_swap_possible = False
+        # if constrained to mesh, change all "split" moves to "migrate", because we cannot split here
+        if config.CONSTRAIN_TOPOLOGY:
+            new_feasible_transformations = set()
+            for t in feasible_transformations:
+                if t == 'split':
+                    new_feasible_transformations.add('migrate')
+                elif t == 'split_swap':
+                    new_feasible_transformations.add('migrate_swap')
+                else:
+                    new_feasible_transformations.add(t)
+                    # migrate_swap_possible = True
+            feasible_transformations = new_feasible_transformations
+        # print(f"## 2 feasible_transformations = {feasible_transformations}")
         # ------------------------
         # based on locality, generate feasible transformations
         # ------------------------
         if can_improve_locality and ('transfer' in config.all_available_transformations):
             # locality not gonna improve area with the current set up
             if not selected_metric == "area" and selected_dir == -1:
-                feasible_transformations.append("transfer")
+                feasible_transformations.add("transfer")
 
         #------------------------
         # there is a on opportunity for routing
         #------------------------
         if can_improve_routing and ('routing' in config.all_available_transformations):
             transformation_list = list(feasible_transformations)
-            transformation_list.append('routing')
+            transformation_list.add('routing')
             feasible_transformations = set(transformation_list)
 
 
         #------------------------
         # post processing of the destination blocks to eliminate transformations
         #------------------------
-        # filter migrate
-        if not found_blck_to_mig_to:
-            # if can't find a block that is at least as good as the current block, can't migrate
-            feasible_transformations =  set(list(set(feasible_transformations) - set(['migrate'])))
 
+        # migrate moves are "no-ops" because we are delegating the mapping job to the scheduling policy
+        if (config.DYN_SCHEDULING_INSTEAD_OF_MAPPING and hot_blck_synced.type == 'pe') or (config.DYN_SCHEDULING_MEM_REMAPPING and hot_blck_synced.type == 'mem'):
+            if "migrate" in feasible_transformations:
+                feasible_transformations.remove("migrate")
+            if "migrate_swap" in feasible_transformations:
+                feasible_transformations.remove("migrate_swap")
+                feasible_transformations.add("swap")
+
+        if 'migrate' in feasible_transformations:
+            # print("Checking if migrate feasible")
+            equal_imm_block_present_for_migration, found_blck_to_mig_to, selection_mode, parallelism_type, locality_type = self.select_block_to_migrate_to(ex_dp, sim_dp, hot_blck_synced,
+                                            selected_metric, sorted_metric_dir, selected_krnl) # , force=(migrant_sel_mode == "mappable_to_same_ip" and self.database.task_is_accelrable_map[selected_krnl.get_task_name()]))
+            # filter migrate
+            if not found_blck_to_mig_to:
+                # if can't find a block that is at least as good as the current block, can't migrate
+                feasible_transformations.remove('migrate')
+
+        # filter migrate_swap
+        # can't migrate_swap if hot task is on an accelerator
+        if "migrate_swap" in feasible_transformations:
+            # print("Checking if migrate_swap feasible")
+            if hot_block_subtype == "ip":
+                feasible_transformations.remove('migrate_swap')
+                # print("[FILTER] 'migrate_swap' filtered out because hot block is IP")
+            # can't migrate_swap if there is no other gpp in the system to migrate non-hot tasks to
+            other_gpp_present = False
+            for b in ex_dp.get_blocks():
+                if hot_blck_synced != b and b.subtype == "gpp":
+                    other_gpp_present = True
+                    break
+            if not other_gpp_present:
+                feasible_transformations.remove('migrate_swap')
+                # print("[FILTER] 'migrate_swap' filtered out because no other GPP found for hosting non-hot tasks")
+
+        # print(f"after mig filters {feasible_transformations}")
         # filter split
         number_of_task_on_block = 0
         if hot_blck_synced.type == "pe":
@@ -824,27 +1033,65 @@
         else:
             number_of_task_on_block = len(hot_blck_synced.get_tasks_of_block_by_dir("write"))
         if number_of_task_on_block == 1:  # can't split an accelerator
-            feasible_transformations =  set(list(set(feasible_transformations) - set(['split', 'split_swap'] )))
-
-        # filter swap
-        block_metric_attr = self.get_block_attr(selected_metric)  # metric to pay attention to
-        if getattr(imm_block, block_metric_attr) == getattr(hot_blck_synced, block_metric_attr):
-            #if imm_block.get_generic_instance_name() == hot_blck_synced.get_generic_instance_name():
-            # if can't swap improve, get rid of swap
-            feasible_transformations = set(list(set(feasible_transformations) - set(['swap'])))
+            if 'split' in feasible_transformations:
+                feasible_transformations.remove('split')
+            if 'split_swap' in feasible_transformations:
+                feasible_transformations.remove('split_swap')
 
         # for IC's we don't use migrate
         if hot_blck_synced.type in ["ic"]:
             # we don't cover migrate for ICs at the moment
             # TODO: add this feature later
-            feasible_transformations = set(list(set(feasible_transformations) - set(['migrate', 'split_swap'])))
+            if 'migrate' in feasible_transformations:
+                feasible_transformations.remove('migrate')
+            if 'split_swap' in feasible_transformations:
+                feasible_transformations.remove('split_swap')
 
-        # if no valid transformation left, issue the identity transformation (where nothing changes and a simple copying is done)
-        if len(list(set(feasible_transformations))) == 0:
-            feasible_transformations = ["identity"]
+        # filter swap
+        block_metric_attr = self.get_block_attr(selected_metric)  # metric to pay attention to
+        # print(f"## imm_block       getattr({imm_block.instance_name}, {block_metric_attr}) = {getattr(imm_block, block_metric_attr)}")
+        # print(f"## hot_blck_synced getattr({hot_blck_synced.instance_name}, {block_metric_attr}) = {getattr(hot_blck_synced, block_metric_attr)}")
+        # print(f"## 1 feasible_transformations = {feasible_transformations}")
+        # if imm_block.get_generic_instance_name() == hot_blck_synced.get_generic_instance_name():
+
+        if not revert_block and 'swap' in feasible_transformations:
+            gpp_blks = [b for b in ex_dp.get_blocks_by_type("pe") if b.subtype == "gpp"]
+            # if there is just one GPP left in the system, then cancel swap for GPP in constrained topology mode
+            if len(gpp_blks) == 1 and config.CONSTRAIN_TOPOLOGY:
+                feasible_transformations.remove('swap')
+            else:
+                if config.CONSTRAIN_TOPOLOGY:
+                    # if we want to improve along one of the metrics and swap is the only thing we can do then we swap a random GPP (if more than one exists in the system) with an IP
+                    if config.DYN_SCHEDULING_INSTEAD_OF_MAPPING and selected_dir == -1 and len(feasible_transformations) == 1:
+                        hot_blck_synced = random.choice(gpp_blks)
+                else:
+                    # if there is just one GPP left in the system, then cancel swap for GPP
+                    if len(gpp_blks) == 1 and hot_block_subtype == "gpp":
+                        feasible_transformations.remove('swap')
+                if 'swap' in feasible_transformations:
+                    # if can't swap improve, get rid of swap
+                    imm_block = self.dh.get_immediate_block_multi_metric(hot_blck_synced, selected_metric, sorted_metric_dir, "swap", selected_krnl, tasks)
+                    if getattr(imm_block, block_metric_attr) == getattr(hot_blck_synced, block_metric_attr):
+                        feasible_transformations.remove('swap')
+                    
+                    # print(f"## imm_block       getattr({imm_block.instance_name}, {block_metric_attr}) = {getattr(imm_block, block_metric_attr)}")
+                    # print(f"## hot_blck_synced getattr({hot_blck_synced.instance_name}, {block_metric_attr}) = {getattr(hot_blck_synced, block_metric_attr)}")
+                    # print(f"## 1 feasible_transformations = {feasible_transformations}")
+        # print(f"## 2 feasible_transformations = {feasible_transformations}")
+
+        # if the hot task has already been specialized for, then cancel split_swaps and splits
+        if (selected_krnl.task_name in self.task_names_specialized_for) and hot_blck_synced.type == 'pe':
+            if 'swap' in feasible_transformations in feasible_transformations:
+                feasible_transformations.remove('swap')
+            elif 'split_swap' in feasible_transformations:
+                feasible_transformations.remove('split_swap')
 
+        # if no valid transformation left, issue the identity transformation (where nothing changes and a simple copying is done)
+        if len(list(feasible_transformations)) == 0:
+            feasible_transformations = set(["identity"])
 
-        return feasible_transformations
+        # print(f"## feasible_transformations = {feasible_transformations}")
+        return list(feasible_transformations), selection_mode, hot_blck_synced
 
     def set_design_space_size(self,  ex_dp, sim_dp):
         # if this knob is set, we randomly pick a transformation
@@ -887,6 +1134,9 @@
                 sim_dp.neighbouring_design_space_size += number_of_task_on_block + 1  # +1 is for split, the rest os for split_swap
 
         for blck in all_blocks:
+            if not blck.get_tasks_of_block():
+                continue
+            # print(f"blck {blck.instance_name} has tasks {[t.name for t in blck.get_tasks_of_block()]}")
             equal_imm_blocks_present_for_migration = self.dh.get_equal_immediate_blocks_present(ex_dp,
                                                                                                 blck,
                                                                                                 "latency",
@@ -899,7 +1149,7 @@
                                                                                                 +1,
                                                                                                     blck.get_tasks_of_block()))
 
-            """ 
+            """
             imm_blocks_present_for_migration.extend([self.dh.get_immediate_block(
                                                                                                      blck,
                                                                                                      "latency",
@@ -922,9 +1172,11 @@
 
 
     def get_transformation_design_space_size(self, move_to_apply, ex_dp, sim_dp, block_of_interest, selected_metric, sorted_metric_dir):
+        if not block_of_interest.get_tasks_of_block():
+            return
         # if this knob is set, we randomly pick a transformation
         # THis is to illustrate the architectural awareness of FARSI a
-        imm_block = self.dh.get_immediate_block_multi_metric(block_of_interest, selected_metric, sorted_metric_dir,  block_of_interest.get_tasks_of_block())
+        # imm_block = self.dh.get_immediate_block_multi_metric(block_of_interest, selected_metric, sorted_metric_dir,  block_of_interest.move_to_apply.krnel, get_tasks_of_block())
 
         task = (block_of_interest.get_tasks_of_block())[0] # any task for do
         feasible_transformations = set(config.metric_trans_dict[selected_metric])
@@ -988,41 +1240,71 @@
     #      selected_krnl: the kernel to focus on
     # ------------------------------
     def select_transformation(self, ex_dp, sim_dp, hot_blck_synced, selected_metric, selected_krnl, sorted_metric_dir):
-        feasible_transformations = self.get_feasible_transformations(ex_dp, sim_dp, hot_blck_synced, selected_metric,
-                                                                    selected_krnl, sorted_metric_dir)
-        if config.print_info_regularly:
-            print(list(feasible_transformations))
-        random.seed(datetime.now().microsecond)
-        # pick randomly at the moment.
-        # TODO: possibly can do better
-        transformation = random.choice(list(feasible_transformations))
+        if config.DYN_SCHEDULING_INSTEAD_OF_MAPPING:
+            tasks = [selected_krnl.get_task()]
+        else:
+            tasks = hot_blck_synced.get_tasks_of_block()
+
+        if self.reverted_last_itr:
+            feasible_transformations = ['identity']
+            transformation = feasible_transformations[0]
+        else:
+
+            # print(f"## hot_blck_synced = {hot_blck_synced.instance_name}, tasks = {[t.name for t in tasks]}")
+            if config.transformation_selection_mode == "arch-aware":
+                feasible_transformations, batch_mode, hot_blck_synced = self.get_feasible_transformations(ex_dp, sim_dp, hot_blck_synced, selected_metric,
+                                                                            selected_krnl, sorted_metric_dir, tasks)
+            elif config.transformation_selection_mode == "random":
+                feasible_transformations = self.get_feasible_transformations(ex_dp, sim_dp, hot_blck_synced, selected_metric,
+                                                                            selected_krnl, sorted_metric_dir, tasks)
+            else: raise NotImplementedError
+            # print(f"feasible_transformations={feasible_transformations}")
+
+            if (config.DEBUG_FIX):
+                random.seed(0)
+            else:
+                random.seed(datetime.now().microsecond)
+            # pick randomly at the moment.
+            # TODO: possibly can do better
+            transformation = random.choice(list(feasible_transformations))
+        # print(f"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!")
+        # print(f"Chose transformation = {transformation} from list {feasible_transformations}")
+        # print(f"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!")
 
         #if len(hot_blck_synced.get_tasks_of_block_by_dir("write")) > 1:
         #    transformation = "split_swap"
         #else:
         #    transformation = "swap"
         if transformation == "migrate":
+            # assert batch_mode == "single" or batch_mode == "batch"
             batch_mode = "single"
             transformation_sub_name = "irrelevant"
         elif transformation == "split":
+            # assert batch_mode == "batch"
             # see if any task can run in parallel
             batch_mode = "batch"
             transformation_sub_name = "irrelevant"
         elif transformation == "split_swap":
+            # assert batch_mode == "single"
             batch_mode = "single"
             transformation_sub_name = "irrelevant"
+        elif transformation == "migrate_swap":
+            # assert batch_mode == "mappable_to_same_ip"
+            batch_mode = "mappable_to_same_ip"
+            transformation_sub_name = "irrelevant"
         elif transformation == "transfer":
+            # assert batch_mode == "single"
             batch_mode = "irrelevant"
             transformation_sub_name = "locality_improvement"
         elif transformation == "routing":
+            # assert batch_mode == "irrelevant"
             batch_mode = "irrelevant"
             transformation_sub_name = "routing_improvement"
         else:
             transformation_sub_name = "irrelevant"
             batch_mode = "irrelevant"
 
-
-        return transformation, transformation_sub_name, batch_mode, len(list(feasible_transformations))
+        return transformation, transformation_sub_name, batch_mode, len(list(feasible_transformations)), tasks, hot_blck_synced
 
     # calculate the cost impact of a kernel improvement
     def get_swap_improvement_cost(self, sim_dp, kernels, selected_metric, dir):
@@ -1040,7 +1322,7 @@
         # Figure out whether there is a mapping that improves kernels performance
         def no_swap_improvement_possible(sim_dp, selected_metric, metric_dir, krnl):
             hot_block = sim_dp.get_dp_stats().get_hot_block_of_krnel(krnl.get_task_name(), selected_metric)
-            imm_block = self.dh.get_immediate_block_multi_metric(hot_block, metric_dir, [krnl.get_task()])
+            imm_block = self.dh.get_immediate_block_multi_metric(hot_block, metric_dir, "swap", krnl, [krnl.get_task()])
             blah  = hot_block.get_generic_instance_name()
             blah2  = imm_block.get_generic_instance_name()
             return hot_block.get_generic_instance_name() == imm_block.get_generic_instance_name()
@@ -1055,7 +1337,7 @@
             current_cost = self.database.db_input.porting_effort[hot_block_subtype]
             #if hot_block_subtype == "ip":
             #    print("what")
-            imm_block = self.dh.get_immediate_block_multi_metric(hot_block,selected_metric, metric_dir,[krnel.get_task()])
+            imm_block = self.dh.get_immediate_block_multi_metric(hot_block,selected_metric, metric_dir, "swap", krnel, [krnel.get_task()])
             imm_block_subtype = get_subtype_for_cost(imm_block)
             imm_block_cost =  self.database.db_input.porting_effort[imm_block_subtype]
             improvement_cost = (imm_block_cost - current_cost)
@@ -1100,7 +1382,7 @@
         hot_block = sim_dp.get_dp_stats().get_hot_block_of_krnel(krnl.get_task_name(), selected_metric)
         hot_block_subtype = get_subtype_for_cost(hot_block)
         current_cost = self.database.db_input.porting_effort[hot_block_subtype]
-        imm_block = self.dh.get_immediate_block_multi_metric(hot_block,selected_metric, sorted_metric_dir,[krnl.get_task()])
+        imm_block = self.dh.get_immediate_block_multi_metric(hot_block,selected_metric, sorted_metric_dir, "swap", krnl, [krnl.get_task()])
         imm_block_subtype = get_subtype_for_cost(imm_block)
         imm_block_cost =  self.database.db_input.porting_effort[imm_block_subtype]
         improvement_cost = (imm_block_cost - current_cost)
@@ -1154,7 +1436,7 @@
         # find cost
         for krnl in krnls:
             hot_block = sim_dp.get_dp_stats().get_hot_block_of_krnel(krnl.get_task_name(), selected_metric)
-            imm_block = self.dh.get_immediate_block_multi_metric(hot_block, selected_metric, move_sorted_metric_dir, [krnl.get_task()])
+            imm_block = self.dh.get_immediate_block_multi_metric(hot_block, selected_metric, move_sorted_metric_dir, trans, krnl, [krnl.get_task()])
             hot_blck_synced = self.dh.find_cores_hot_kernel_blck_bottlneck(ex_dp, hot_block)
             feasible_trans = self.get_feasible_transformations(ex_dp, sim_dp, hot_blck_synced, selected_metric,
                                               krnl,move_sorted_metric_dir)
@@ -1169,9 +1451,10 @@
         metric_prob_dict = {}  # (metric:priority value) each value is in [0 ,1] interval
         for metric in config.budgetted_metrics:
             metric_prob_dict[metric] = sim_dp.dp_stats.dist_to_goal_per_metric(metric, config.metric_sel_dis_mode)/\
-                                                   sim_dp.dp_stats.dist_to_goal(["power", "area", "latency"],
+                                                   sim_dp.dp_stats.dist_to_goal(config.budgetted_metrics, # ["power", "area", "latency"],
                                                                                 config.metric_sel_dis_mode)
 
+        # pprint(metric_prob_dict)
         # sort the metric based on distance (and whether the sort is probabilistic or exact).
         # probabilistic sorting, first sort exactly, then use the exact value as a probability of selection
         metric_prob_dict_sorted = {k: v for k, v in sorted(metric_prob_dict.items(), key=lambda item: item[1])}
@@ -1187,11 +1470,7 @@
                 move_dir = -1  # try to reduce the metric value
             sorted_low_to_high_metric_dir[metric] = move_dir
 
-        # Delete later. for now for validation
-        #selected_metric = "latency"
-        #sorted_low_to_high_metric_dir=  {'area':1, 'power':-1, 'latency':-1}
-        #metric_prob_dict_sorted =  {'area':.1, 'power':.1, 'latency':.8}
-
+        # print(f"@@ selected_metric = {selected_metric}, move_dir = {move_dir}")
         return selected_metric, metric_prob_dict_sorted, sorted_low_to_high_metric_dir
 
     # select direction for the move
@@ -1221,25 +1500,9 @@
         return krnls_to_consider
 
     # get each kernels_contribution to the metric of interest
+    @abstractmethod
     def get_kernels_s_contribution(self, selected_metric, sim_dp):
-        krnl_prob_dict = {}  # (kernel, metric_value)
-
-
-        #krnls = sim_dp.get_dp_stats().get_kernels()
-        # filter it kernels whose workload meet the budget
-        krnls = self.filter_in_kernels_meeting_budget(selected_metric, sim_dp)
-        if krnls == []: # the design meets the budget, hence all kernels can be improved for cost improvement
-            krnls = sim_dp.get_dp_stats().get_kernels()
-
-        metric_total = sum([krnl.stats.get_metric(selected_metric) for krnl in krnls])
-        # sort kernels based on their contribution to the metric of interest
-        for krnl in krnls:
-            krnl_prob_dict[krnl] = krnl.stats.get_metric(selected_metric)/metric_total
-
-        if not "bottleneck" in self.move_s_krnel_selection:
-            for krnl in krnls:
-                krnl_prob_dict[krnl] = 1
-        return krnl_prob_dict
+        pass
 
     # get each_kernels_improvement_ease (ease = 1/cost)
     def get_kernels_s_improvement_ease(self, ex_dp, sim_dp, selected_metric, move_sorted_metric_dir):
@@ -1270,48 +1533,9 @@
         return krnl_improvement_ease
 
     # select the kernel for the move
+    @abstractmethod
     def select_kernel(self, ex_dp, sim_dp, selected_metric, move_sorted_metric_dir):
-
-        # get each kernel's contributions
-        krnl_contribution_dict = self.get_kernels_s_contribution(selected_metric, sim_dp)
-        # get each kernel's improvement cost
-        krnl_improvement_ease = self.get_kernels_s_improvement_ease(ex_dp, sim_dp, selected_metric, move_sorted_metric_dir)
-
-
-
-
-        # combine the selections methods
-        # multiply the probabilities for a more complex metric
-        krnl_prob_dict = {}
-        for krnl in krnl_contribution_dict.keys():
-            krnl_prob_dict[krnl] = krnl_contribution_dict[krnl] * krnl_improvement_ease[krnl]
-
-        # give zero probablity to the krnls that you filtered out
-        for krnl in sim_dp.get_dp_stats().get_kernels():
-            if krnl not in krnl_prob_dict.keys():
-                krnl_prob_dict[krnl] = 0
-        # sort
-        #krnl_prob_dict_sorted = {k: v for k, v in sorted(krnl_prob_dict.items(), key=lambda item: item[1])}
-        krnl_prob_dict_sorted = sorted(krnl_prob_dict.items(), key=lambda item: item[1], reverse=True)
-
-        # get the worse kernel
-        if config.move_krnel_ranking_mode == "exact":  # for area to allow us pick scenarios that are not necessarily the worst
-            #selected_krnl = list(krnl_prob_dict_sorted.keys())[
-            #    len(krnl_prob_dict_sorted.keys()) - 1 - self.krnel_rnk_to_consider]
-            for krnl, prob in krnl_prob_dict_sorted:
-                if krnl.get_task_name() in self.krnels_not_to_consider:
-                    continue
-                selected_krnl = krnl
-                break
-        else:
-            selected_krnl = self.pick_from_prob_dict(krnl_prob_dict_sorted)
-
-        if config.transformation_selection_mode == "random":
-            krnls = sim_dp.get_dp_stats().get_kernels()
-            random.seed(datetime.now().microsecond)
-            selected_krnl = random.choice(krnls)
-
-        return selected_krnl, krnl_prob_dict, krnl_prob_dict_sorted
+        pass
 
     # select blocks for the move
     def select_block(self, sim_dp, ex_dp, selected_krnl, selected_metric):
@@ -1320,8 +1544,11 @@
 
         # randomly pick one
         if config.transformation_selection_mode =="random":
-            random.seed(datetime.now().microsecond)
-            hot_blck = any_block = random.choice(ex_dp.get_hardware_graph().get_blocks())  # this is just dummmy to prevent breaking the plotting
+            if (config.DEBUG_FIX):
+                random.seed(0)
+            else:
+                random.seed(datetime.now().microsecond)
+            hot_blck = random.choice(selected_krnl.get_blocks())
 
         # hot_blck_synced is the same block but ensured that the block instance
         # is chosen from ex instead of sim, so it can be modified
@@ -1398,7 +1625,7 @@
 
         ic_entry, ic_exit = None, None
         for mem in mems:
-            path= sim_dp.dp.get_hardware_graph().get_path_between_two_vertecies(pe, mem)
+            path= sim_dp.dp.get_hardware_graph().get_path_between_two_vertices(pe, mem)
             if len(path)> 4:  # more than two ICs
                 ic_entry = path[1]
                 ic_exit = path[-2]
@@ -1417,7 +1644,7 @@
         mems =[blk for blk in task_s_blocks if blk.type == "mem"]
 
         for mem in mems:
-            path= ex_dp.get_hardware_graph().get_path_between_two_vertecies(pe, mem)
+            path= ex_dp.get_hardware_graph().get_path_between_two_vertices(pe, mem)
             if len(path) > 4:  # more than two ICs
                 return True
         return False
@@ -1526,11 +1753,11 @@
         t_3 = time.time()
         selected_block, block_prob_dict = self.select_block(sim_dp, ex_dp, selected_krnl, selected_metric)
         t_4 = time.time()
-        transformation_name,transformation_sub_name, transformation_batch_mode, total_transformation_cnt = self.select_transformation(ex_dp, sim_dp, selected_block, selected_metric, selected_krnl, sorted_metric_dir)
+        transformation_name,transformation_sub_name, transformation_batch_mode, total_transformation_cnt, tasks, selected_block = self.select_transformation(ex_dp, sim_dp, selected_block, selected_metric, selected_krnl, sorted_metric_dir)
         t_5 = time.time()
 
-        self.set_design_space_size(des_tup[0], des_tup[1])
-
+        if not config.DYN_SCHEDULING_INSTEAD_OF_MAPPING:
+            self.set_design_space_size(des_tup[0], des_tup[1])
 
         """
         if sim_dp.dp_stats.fits_budget(1) and self.dram_feasibility_check_pass(ex_dp) and self.can_improve_locality(selected_block, selected_krnl):
@@ -1566,14 +1793,14 @@
         move_to_apply.set_logs(metric_prob_dir_dict, "metrics")
         move_to_apply.set_logs(block_prob_dict, "blocks")
         move_to_apply.set_logs(self.krnel_rnk_to_consider, "kernel_rnk_to_consider")
-        move_to_apply.set_logs(sim_dp.dp_stats.dist_to_goal(["power", "area", "latency", "cost"],
+        move_to_apply.set_logs(sim_dp.dp_stats.dist_to_goal(config.budgetted_metrics,
                                                                                 config.metric_sel_dis_mode),"ref_des_dist_to_goal_all")
-        move_to_apply.set_logs(sim_dp.dp_stats.dist_to_goal(["power", "area", "latency"],
+        move_to_apply.set_logs(sim_dp.dp_stats.dist_to_goal([metric for metric in config.budgetted_metrics if metric != "cost"],
                                                                                 config.metric_sel_dis_mode),"ref_des_dist_to_goal_non_cost")
 
-        for blck_of_interest in ex_dp.get_blocks():
-            self.get_transformation_design_space_size(move_to_apply, ex_dp, sim_dp, blck_of_interest, selected_metric, sorted_metric_dir)
-
+        if not config.DYN_SCHEDULING_INSTEAD_OF_MAPPING:
+            for blck_of_interest in ex_dp.get_blocks():
+                self.get_transformation_design_space_size(move_to_apply, ex_dp, sim_dp, blck_of_interest, selected_metric, sorted_metric_dir)
 
         move_to_apply.set_logs(t_1 - t_0, "metric_selection_time")
         move_to_apply.set_logs(t_2 - t_1, "dir_selection_time")
@@ -1598,14 +1825,36 @@
             else:
                 self.dh.unload_read_buses(ex_dp)  # unload buses
             # get immediate superior/inferior block (based on the desired direction)
-            imm_block = self.dh.get_immediate_block_multi_metric(blck_ref,
-                                                 move_to_apply.get_metric(), move_to_apply.get_sorted_metric_dir(),
-                                                 blck_ref.get_tasks_of_block())  # immediate block either superior or
+            revert_block = False
+            if config.DYN_SCHEDULING_INSTEAD_OF_MAPPING and config.CONSTRAIN_TOPOLOGY:
+                tasks = [selected_krnl.get_task()]
+                # if an existing IP that could run the hot task if sitting idle, it means that the scheduler cannot make use of yet another one,
+                # so, we will reverse this swap move to swap that idle IP with a GPP
+                for b in ex_dp.get_hardware_graph().get_blocks():
+                    if len(b.get_tasks_of_block()) == 0 and b.type == "pe" and b.subtype != "gpp" and b.instance_type in self.database.task_to_mappable_pe_map[selected_krnl.get_task_name()]:
+                        print(f"Reverting block {b.instance_name} to GPP")
+                        revert_block = True
+                        blck_ref = b
+                        break
+                if not revert_block:
+                    # record for swap
+                    self.task_names_specialized_for.add(selected_krnl.get_task_name())
+            if revert_block:
+                imm_block = self.dh.get_immediate_block_fast(blck_ref, "latency", 1, tasks)
+                # imm_block = self.database.up_sample_down_sample_block_fast(blck_ref, "latency", 1, tasks)[0]
+                move_to_apply.set_ref_block(blck_ref)
+                # self.reverted_last_itr = True
+                self.add_to_krnels_not_to_consider(ex_dp, self.last_move_kernel.get_task_name())
+            else:
+                imm_block = self.dh.get_immediate_block_multi_metric(blck_ref,
+                                                    move_to_apply.get_metric(), move_to_apply.get_sorted_metric_dir(), move_to_apply.get_transformation_name(),
+                                                    move_to_apply.get_kernel_ref(), tasks)  # immediate block either superior or
+            # print(f"@@ imm_block: {imm_block.instance_name}")
             move_to_apply.set_dest_block(imm_block)
             move_to_apply.set_customization_type(blck_ref, imm_block)
 
             move_to_apply.set_tasks(blck_ref.get_tasks_of_block())
-        elif move_to_apply.get_transformation_name() in ["split_swap"]:
+        elif move_to_apply.get_transformation_name() in ["split_swap", "migrate_swap"]:
             self.dh.unload_buses(ex_dp)  # unload buses
             # get immediate superior/inferior block (based on the desired direction)
             succeeded,migrant = blck_ref.get_tasks_by_name(move_to_apply.get_kernel_ref().get_task_name())
@@ -1613,17 +1862,44 @@
                 move_to_apply.set_validity(False, "NoMigrantException")
             else:
                 imm_block = self.dh.get_immediate_block_multi_metric(blck_ref,
-                                                     move_to_apply.get_metric(), move_to_apply.get_sorted_metric_dir(),
-                                                     [migrant])  # immediate block either superior or
+                                                     move_to_apply.get_metric(), move_to_apply.get_sorted_metric_dir(), move_to_apply.get_transformation_name(),
+                                                     move_to_apply.get_kernel_ref(), [migrant])  # immediate block either superior or
                 move_to_apply.set_dest_block(imm_block)
 
                 self.dh.unload_read_mem(ex_dp)  # unload memories
                 self.change_read_task_to_write_if_necessary(ex_dp, sim_dp, move_to_apply, selected_krnl)
-                migrant_tasks = self.dh.migrant_selection(ex_dp, sim_dp, blck_ref, blck_ref_cp, move_to_apply.get_kernel_ref(),
-                                                          move_to_apply.get_transformation_batch())
-                #migrant_tasks  = list(set(move_to_apply.get_block_ref().get_tasks()) - set(migrant_tasks_))  # reverse the order to allow for swap to happen on the ref_block
-                move_to_apply.set_tasks(migrant_tasks)
-                move_to_apply.set_customization_type(blck_ref, imm_block)
+                if move_to_apply.get_transformation_name() == "migrate_swap":
+                    imm_block_present, found_blck_to_mig_to, mig_selection_mode, _, _ = self.select_block_to_migrate_to(ex_dp,
+                                                                                                    sim_dp,
+                                                                                                    blck_ref_cp,
+                                                                                                    move_to_apply.get_metric(),
+                                                                                                    move_to_apply.get_sorted_metric_dir(),
+                                                                                                    move_to_apply.get_kernel_ref(), True)
+                    if not imm_block_present.subtype == "ip":
+                        self.change_read_task_to_write_if_necessary(ex_dp, sim_dp, move_to_apply, selected_krnl)
+                        if not found_blck_to_mig_to:
+                            move_to_apply.set_validity(False, "NoMigrantException")
+                            imm_block_present = blck_ref
+                        elif move_to_apply.get_kernel_ref().get_task().is_task_dummy():
+                            move_to_apply.set_validity(False, "NoMigrantException")
+                            imm_block_present = blck_ref
+                        else:
+                            migrant_tasks = self.dh.migrant_selection(ex_dp, sim_dp, blck_ref, blck_ref_cp, move_to_apply.get_kernel_ref(),
+                                                                    mig_selection_mode, imm_block.instance_name.split('_pe')[0], imm_block_present.instance_name.split('_pe')[0])
+                            move_to_apply.set_dest_block(imm_block_present) # destination to move tasks to
+                            move_to_apply.set_swap_dest_block(imm_block) # destination to swap with
+                            move_to_apply.set_tasks(migrant_tasks)
+                            move_to_apply.set_customization_type(blck_ref, imm_block)
+                        move_to_apply.set_validity(False, "NoMigrantException")
+                        imm_block_present = blck_ref
+                else:
+                    migrant_tasks = self.dh.migrant_selection(ex_dp, sim_dp, blck_ref, blck_ref_cp, move_to_apply.get_kernel_ref(),
+                                                            move_to_apply.get_transformation_batch())
+                    move_to_apply.set_tasks(migrant_tasks)
+                    move_to_apply.set_customization_type(blck_ref, imm_block)
+                    # record for split_swap
+                    if blck_ref.type == 'pe':
+                        self.task_names_specialized_for.add(selected_krnl.get_task_name())
         elif move_to_apply.get_transformation_name() in ["split"]:
             # select tasks to migrate
             #self.change_read_task_to_write_if_necessary(ex_dp, sim_dp, move_to_apply, selected_krnl)
@@ -1641,12 +1917,13 @@
 
             move_to_apply.set_parallelism_type(parallelism_type)
             move_to_apply.set_tasks(migrant_tasks)
-            if len(migrant_tasks) == 0:
-                move_to_apply.set_validity(False, "NoParallelTaskException")
-            if blck_ref.subtype == "ip": # makes no sense to split the IPs,
-                                                              # it can actually cause problems where
-                                                              # we end up duplicating the hardware
-                move_to_apply.set_validity(False, "IPSplitException")
+            if not config.DYN_SCHEDULING_INSTEAD_OF_MAPPING:
+                if len(migrant_tasks) == 0:
+                    move_to_apply.set_validity(False, "NoParallelTaskException")
+                if blck_ref.subtype == "ip": # makes no sense to split the IPs,
+                                                                # it can actually cause problems where
+                                                                # we end up duplicating the hardware
+                    move_to_apply.set_validity(False, "IPSplitException")
         elif move_to_apply.get_transformation_name() == "migrate":
             if not selected_block.type == "ic":  # ic migration is not supported
                 # check and see if tasks exist (if not, it was a read)
@@ -1658,7 +1935,6 @@
                                                                                                               move_to_apply.get_kernel_ref())
 
 
-
                 move_to_apply.set_parallelism_type(parallelism_type)
                 move_to_apply.set_locality_type(locality_type)
                 self.dh.unload_buses(ex_dp)  # unload buses
@@ -1668,13 +1944,12 @@
                 if not found_blck_to_mig_to:
                     move_to_apply.set_validity(False, "NoMigrantException")
                     imm_block_present = blck_ref
-                elif move_to_apply.get_kernel_ref().get_task_name() in ["souurce", "siink", "dummy_last"]:
+                elif move_to_apply.get_kernel_ref().get_task().is_task_dummy():
                     move_to_apply.set_validity(False, "NoMigrantException")
                     imm_block_present = blck_ref
                 else:
                     migrant_tasks = self.dh.migrant_selection(ex_dp, sim_dp, blck_ref, blck_ref_cp, move_to_apply.get_kernel_ref(),
                                                               mig_selection_mode)
-
                     move_to_apply.set_tasks(migrant_tasks)
                     move_to_apply.set_dest_block(imm_block_present)
             else:
@@ -1741,7 +2016,6 @@
                             move_to_apply.set_tasks(migrant_tasks)
                             move_to_apply.set_dest_block(imm_block_present)
 
-
         move_to_apply.set_breadth_depth(self.SA_current_breadth, self.SA_current_depth, self.SA_current_mini_breadth)  # set depth and breadth (for debugging/ plotting)
         return move_to_apply, total_transformation_cnt
 
@@ -1870,6 +2144,10 @@
 
                     return sim_dp_to_select_from[0], False
 
+    def found_soc_design_code_in_cache(self, cand_soc_design_code, cached_soc_design_codes):
+        assert cand_soc_design_code != None
+        found = (cand_soc_design_code in cached_soc_design_codes)
+        return (found, cand_soc_design_code)
 
     # find the best design from a list
     def find_best_design_others(self, sim_stat_ex_dp_dict, sim_dp_stat_ann_delta_energy_dict, sim_dp_stat_ann_delta_energy_dict_all_metrics, best_sim_dp_stat_so_far, best_ex_dp_so_far):
@@ -1949,7 +2227,6 @@
                 else:
                     return designs_to_consider[0], True # can be smarter here
 
-
     # use simulated annealing to pick the next design(s).
     # Use this link to understand simulated annealing (SA) http://www.cs.cmu.edu/afs/cs.cmu.edu/project/learn-43/lib/photoz/.g/we /glossary/anneal.html
     # cur_temp: current temperature for simulated annealing
@@ -1969,7 +2246,6 @@
                 return krnl.get_task_name()
 
 
-
         # get the kernel of interest using this for now to collect cached designs
         best_sim_selected_metric, metric_prob_dict,best_sorted_metric_dir = self.select_metric(best_sim_dp_so_far_stats.dp)
         best_sim_move_dir = self.select_dir(best_sim_dp_so_far_stats.dp, best_sim_selected_metric)
@@ -2065,10 +2341,7 @@
                 if not sim_dp_.move_applied == None:
                     sim_dp_.move_applied.print_info()
                     print("energy" + str(energy))
-                    print("design's latency: " + str(el.get_system_complex_metric("latency")))
-                    print("design's power: " + str(el.get_system_complex_metric("power")))
-                    print("design's area: " + str(el.get_system_complex_metric("area")))
-                    print("design's sub area: " + str(el.get_system_complex_area_stacked_dram()))
+                    el.print_summary()
 
         # if any negative (desired move) value is detected or there is a design in the new batch
         #  that meet the budget, but the previous best design didn't, we have at least one improved solution
@@ -2084,30 +2357,30 @@
             self.krnel_stagnation_ctr +=1
             self.des_stag_ctr += 1
             if self.krnel_stagnation_ctr > config.max_krnel_stagnation_ctr:
-                self.krnel_rnk_to_consider = min(self.krnel_rnk_to_consider + 1, len(best_sim_dp_so_far_stats.get_kernels()) -1)
+                self.krnel_rnk_to_consider = min(self.krnel_rnk_to_consider + 1, len(best_sim_dp_so_far_stats.get_kernels()) -1) # todo unused
                 krnel_not_to_consider = get_kernel_not_to_consider(self.krnels_not_to_consider, best_sim_dp_so_far_stats.dp.move_applied, sim_dp_to_look_at[-1].dp.move_applied)
                 if not krnel_not_to_consider == None:
-                    self.krnels_not_to_consider.append(krnel_not_to_consider)
-                #self.krnel_stagnation_ctr = 0
-                #self.recently_seen_design_ctr = 0
-        elif best_neighbour_stat.dp.dp_rep.get_hardware_graph().get_SOC_design_code() in self.recently_cached_designs[best_sim_selected_krnl.get_task_name()] and False:
-            # avoid circular exploration
-            self.recently_seen_design_ctr += 1
-            self.des_stag_ctr += 1
-            if self.recently_seen_design_ctr > config.max_recently_seen_design_ctr:
-                self.krnel_rnk_to_consider = min(self.krnel_rnk_to_consider + 1,
-                                                 len(best_sim_dp_so_far_stats.get_kernels()) - 1)
-                self.krnel_stagnation_ctr = 0
-                #self.recently_seen_design_ctr = 0
+                    self.add_to_krnels_not_to_consider(best_ex_dp_so_far, krnel_not_to_consider)
         else:
-            self.krnel_stagnation_ctr = max(0, self.krnel_stagnation_ctr -1)
-            if self.krnel_stagnation_ctr == 0:
-                if not len(self.krnels_not_to_consider) == 0:
-                    self.krnels_not_to_consider = self.krnels_not_to_consider[:-1]
-                self.krnel_rnk_to_consider = max(0, self.krnel_rnk_to_consider - 1)
-            self.cleanup_ctr +=1
-            self.des_stag_ctr = 0
-            self.recently_seen_design_ctr = 0
+            found_soc = self.found_soc_design_code_in_cache(best_neighbour_stat.dp.dp_rep.get_hardware_graph().get_SOC_design_code(), self.recently_cached_designs[best_sim_selected_krnl.get_task_name()])[0]
+            if found_soc and False:
+                # avoid circular exploration
+                self.recently_seen_design_ctr += 1
+                self.des_stag_ctr += 1
+                if self.recently_seen_design_ctr > config.max_recently_seen_design_ctr:
+                    self.krnel_rnk_to_consider = min(self.krnel_rnk_to_consider + 1,
+                                                    len(best_sim_dp_so_far_stats.get_kernels()) - 1)
+                    self.krnel_stagnation_ctr = 0
+                    #self.recently_seen_design_ctr = 0
+            else:
+                self.krnel_stagnation_ctr = max(0, self.krnel_stagnation_ctr -1)
+                if self.krnel_stagnation_ctr == 0:
+                    if not len(self.krnels_not_to_consider) == 0:
+                        self.remove_from_krnels_not_to_consider(best_ex_dp_so_far, self.krnels_not_to_consider[-1])
+                    self.krnel_rnk_to_consider = max(0, self.krnel_rnk_to_consider - 1)
+                self.cleanup_ctr +=1
+                self.des_stag_ctr = 0
+                self.recently_seen_design_ctr = 0
 
         # initialize selected_sim_dp
         selected_sim_dp = best_sim_dp_so_far_stats.dp
@@ -2186,24 +2459,23 @@
         metric_to_target , metric_prob_dict, sorted_metric_dir = self.select_metric(best_sim_dp_so_far_stats.dp)
         include_cost_in_distance = best_sim_dp_so_far_stats.fits_budget(1) or (len(new_designs_meeting_budget) > 0) or self.is_cleanup_iter() or (len(new_designs_meeting_budget_with_dram)>0)
         if include_cost_in_distance:
-            ann_energy_best_dp_so_far = best_sim_dp_so_far_stats.dist_to_goal(["cost", "latency", "power", "area"],
+            ann_energy_best_dp_so_far = best_sim_dp_so_far_stats.dist_to_goal(config.budgetted_metrics,
                                                                               "eliminate")
-            ann_energy_best_dp_so_far_all_metrics = best_sim_dp_so_far_stats.dist_to_goal(["cost", "latency", "power", "area"],
+            ann_energy_best_dp_so_far_all_metrics = best_sim_dp_so_far_stats.dist_to_goal(config.budgetted_metrics,
                                                                               "eliminate")
         else:
             ann_energy_best_dp_so_far = best_sim_dp_so_far_stats.dist_to_goal([metric_to_target], "dampen")
-            ann_energy_best_dp_so_far_all_metrics = best_sim_dp_so_far_stats.dist_to_goal(["power", "area", "latency"],
+            ann_energy_best_dp_so_far_all_metrics = best_sim_dp_so_far_stats.dist_to_goal([metric for metric in config.budgetted_metrics if metric != "cost"],
                                                                               "dampen")
+
         sim_dp_stat_ann_delta_energy_dict = {}
         sim_dp_stat_ann_delta_energy_dict_all_metrics = {}
         # deleteee the following debugging lines
         print("--------%%%%%%%%%%%---------------")
         print("--------%%%%%%%%%%%---------------")
         print("first the best design from the previous iteration")
-        print(" des" + " latency:" + str(best_sim_dp_so_far_stats.get_system_complex_metric("latency")))
-        print(" des" + " power:" + str(
-            best_sim_dp_so_far_stats.get_system_complex_metric("power")))
         print("energy :" + str(ann_energy_best_dp_so_far))
+        best_sim_dp_so_far_stats.print_summary(prefix=" ")
 
 
 
@@ -2216,16 +2488,17 @@
         else:
             sim_dp_to_look_at = sim_dp_stat_list
 
-        for sim_dp_stat in sim_dp_to_look_at:
+        for i, sim_dp_stat in enumerate(sim_dp_to_look_at):
             if include_cost_in_distance:
                 sim_dp_stat_ann_delta_energy_dict[sim_dp_stat] = sim_dp_stat.dist_to_goal(
-                    ["cost", "latency", "power", "area"], "eliminate") - ann_energy_best_dp_so_far
+                    config.budgetted_metrics, "eliminate") - ann_energy_best_dp_so_far
                 sim_dp_stat_ann_delta_energy_dict_all_metrics[sim_dp_stat] = sim_dp_stat.dist_to_goal(
-                    ["cost", "latency", "power", "area"], "eliminate") - ann_energy_best_dp_so_far_all_metrics
+                    config.budgetted_metrics, "eliminate") - ann_energy_best_dp_so_far_all_metrics
             else:
                 new_design_energy = sim_dp_stat.dist_to_goal([metric_to_target], "dampen")
                 sim_dp_stat_ann_delta_energy_dict[sim_dp_stat] = new_design_energy - ann_energy_best_dp_so_far
-                new_design_energy_all_metrics = sim_dp_stat.dist_to_goal(["power", "latency", "area"], "dampen")
+                new_design_energy_all_metrics = sim_dp_stat.dist_to_goal([metric for metric in config.budgetted_metrics if metric != "cost"], "dampen")
+
                 sim_dp_stat_ann_delta_energy_dict_all_metrics[sim_dp_stat] = new_design_energy_all_metrics - ann_energy_best_dp_so_far_all_metrics
 
         # changing the seed for random selection
@@ -2239,14 +2512,11 @@
         print("all the designs tried")
         for el, energy in sim_dp_stat_ann_delta_energy_dict_all_metrics.items():
             print("----------------")
-            sim_dp_ =  el.dp
+            sim_dp_ = el.dp
             if not sim_dp_.move_applied == None:
                 sim_dp_.move_applied.print_info()
                 print("energy" + str(energy))
-                print("design's latency: " + str(el.get_system_complex_metric("latency")))
-                print("design's power: " + str(el.get_system_complex_metric("power")))
-                print("design's area: " + str(el.get_system_complex_metric("area")))
-                print("design's sub area: " + str(el.get_system_complex_area_stacked_dram()))
+                el.print_summary()
 
         # if any negative (desired move) value is detected or there is a design in the new batch
         #  that meet the budget, but the previous best design didn't, we have at least one improved solution
@@ -2265,27 +2535,32 @@
                 self.krnel_rnk_to_consider = min(self.krnel_rnk_to_consider + 1, len(best_sim_dp_so_far_stats.get_kernels()) -1)
                 krnel_not_to_consider = get_kernel_not_to_consider(self.krnels_not_to_consider, best_sim_dp_so_far_stats.dp.move_applied, sim_dp_to_look_at[-1].dp.move_applied)
                 if not krnel_not_to_consider == None:
-                    self.krnels_not_to_consider.append(krnel_not_to_consider)
+                    self.add_to_krnels_not_to_consider(best_ex_dp_so_far, krnel_not_to_consider)
                 #self.krnel_stagnation_ctr = 0
                 #self.recently_seen_design_ctr = 0
-        elif best_neighbour_stat.dp.dp_rep.get_hardware_graph().get_SOC_design_code() in self.recently_cached_designs[best_sim_selected_krnl.get_task_name()] and False:
-            # avoid circular exploration
-            self.recently_seen_design_ctr += 1
-            self.des_stag_ctr += 1
-            if self.recently_seen_design_ctr > config.max_recently_seen_design_ctr:
-                self.krnel_rnk_to_consider = min(self.krnel_rnk_to_consider + 1,
-                                                 len(best_sim_dp_so_far_stats.get_kernels()) - 1)
-                self.krnel_stagnation_ctr = 0
-                #self.recently_seen_design_ctr = 0
         else:
-            self.krnel_stagnation_ctr = max(0, self.krnel_stagnation_ctr -1)
-            if self.krnel_stagnation_ctr == 0:
-                if not len(self.krnels_not_to_consider) == 0:
-                    self.krnels_not_to_consider = self.krnels_not_to_consider[:-1]
-                self.krnel_rnk_to_consider = max(0, self.krnel_rnk_to_consider - 1)
-            self.cleanup_ctr +=1
-            self.des_stag_ctr = 0
-            self.recently_seen_design_ctr = 0
+            found_soc = self.found_soc_design_code_in_cache(best_neighbour_stat.dp.dp_rep.get_hardware_graph().get_SOC_design_code(), self.recently_cached_designs[best_sim_selected_krnl.get_task_name()])[0]
+            if found_soc and False:
+                # avoid circular exploration
+                self.recently_seen_design_ctr += 1
+                self.des_stag_ctr += 1
+                if self.recently_seen_design_ctr > config.max_recently_seen_design_ctr:
+                    self.krnel_rnk_to_consider = min(self.krnel_rnk_to_consider + 1,
+                                                    len(best_sim_dp_so_far_stats.get_kernels()) - 1)
+                    self.krnel_stagnation_ctr = 0
+                    #self.recently_seen_design_ctr = 0
+            else:
+                self.krnel_stagnation_ctr = max(0, self.krnel_stagnation_ctr -1)
+                if self.krnel_stagnation_ctr == 0:
+                    if not len(self.krnels_not_to_consider) == 0:
+                        self.remove_from_krnels_not_to_consider(best_ex_dp_so_far, self.krnels_not_to_consider[-1])
+                    self.krnel_rnk_to_consider = max(0, self.krnel_rnk_to_consider - 1)
+                self.cleanup_ctr +=1
+                self.des_stag_ctr = 0
+                self.recently_seen_design_ctr = 0
+
+
+        # print(f"** kernels not to consider: {self.krnels_not_to_consider}")
 
         # initialize selected_sim_dp
         selected_sim_dp = best_sim_dp_so_far_stats.dp
@@ -2422,11 +2697,11 @@
         if config.simulation_method == "power_knobs":
             sim_dp = self.dh.convert_to_sim_des_point(ex_dp)
             power_knob_sim_dp = self.dh.convert_to_sim_des_point(ex_dp)
-            OSA = OSASimulator(sim_dp, database, power_knob_sim_dp)
+            OSA = OSASimulator(sim_dp, self.dh, database, power_knob_sim_dp)
         else:
             sim_dp = self.dh.convert_to_sim_des_point(ex_dp)
             # Simulator initialization
-            OSA = OSASimulator(sim_dp, database)  # change
+            OSA = OSASimulator(sim_dp, self.dh, database)  # change
 
         # Does the actual simulation
         t = time.time()
@@ -2439,7 +2714,7 @@
         sim_dp.set_depth_number(self.SA_current_depth)
         sim_dp.set_simulation_time(sim_time)
 
-        #print("sim time" + str(sim_time))
+        print("sim time" + str(sim_time))
         #exit(0)
         return sim_dp
 
@@ -2564,14 +2839,21 @@
             return self.sim_one_design(ex_dp, database) # evaluation the design directly
         elif config.eval_mode == "statistical":
             # generate a population (geneate_sample), evaluate them and reduce to some statistical indicator
-            ex_dp_pop_sample = [self.generate_sample(ex_dp, database.hw_sampling) for i in range(0, self.database.hw_sampling["population_size"])] # population sample
+            if self.database.hw_sampling["population_size"] == 1:
+                ex_dp_pop_sample = [ex_dp]
+            else:
+                ex_dp_pop_sample = [self.generate_sample(ex_dp, database.hw_sampling) for i in range(0, self.database.hw_sampling["population_size"])] # population sample
             ex_dp.get_tasks()[0].task_id_for_debugging_static += 1
+            # perform the simulation
             sim_dp_pop_sample = list(map(lambda ex_dp_: self.sim_one_design(ex_dp_, database), ex_dp_pop_sample)) # evaluate the population sample
 
             # collect profiling information
             sim_dp_statistical = SimDesignPointContainer(sim_dp_pop_sample, database, config.statistical_reduction_mode)
             #print("time is:" + str(time.time() -start))
-            return sim_dp_statistical
+            if config.DYN_SCHEDULING_INSTEAD_OF_MAPPING:
+                return ex_dp_pop_sample[0], sim_dp_statistical
+            else:
+                return sim_dp_statistical
         else:
             print("mode" + config.eval_mode + " is not defined for eval design")
 
@@ -2587,12 +2869,8 @@
         # iterate till you can make a directory
         while True:
             date_time = datetime.now().strftime('%m-%d_%H-%M_%S')
-            #result_folder = os.path.join(self.result_dir, "data_per_design",
-            #                             date_time+"_"+str(self.name_ctr))
-            # one for PA data collection
-            result_folder = os.path.join(self.result_dir+"/../../", "data_per_design",
+            result_folder = os.path.join(self.result_dir, "data_per_design",
                                          date_time+"_"+str(self.name_ctr))
-
             if not os.path.isdir(result_folder):
                 os.makedirs(result_folder)
                 collection_ctr = self.name_ctr # used to realize which results to compare
@@ -2656,6 +2934,7 @@
     def gen_neigh_and_eval(self, des_tup):
         # "delete this later"
         print("------ depth ------")
+
         # generate on neighbour
         move_strt_time = time.time()
         ex_dp, move_to_try,total_trans_cnt = self.gen_one_neigh(des_tup)
@@ -2669,14 +2948,19 @@
         if move_to_try.get_transformation_name() == "identity" or not move_to_try.is_valid():
             # if nothing has changed, just copy the sim from before
             sim_dp = des_tup[1]
-        elif design_unique_code not in self.cached_SOC_sim.keys():
-            self.population_observed_ctr += 1
-            sim_dp = self.eval_design(ex_dp, self.database)  # evaluate the designs
-            #if config.cache_seen_designs: # this seems to be slower than just simulation, because of deepcopy
-            #    self.cached_SOC_sim[design_unique_code] = (ex_dp, sim_dp)
         else:
-            ex_dp = self.cached_SOC_sim[design_unique_code][0]
-            sim_dp = self.cached_SOC_sim[design_unique_code][1]
+            found_soc, cached_soc = self.found_soc_design_code_in_cache(design_unique_code, self.cached_SOC_sim.keys())
+            if not found_soc:
+                self.population_observed_ctr += 1   # total number of unique designs simulated
+                if config.DYN_SCHEDULING_INSTEAD_OF_MAPPING:
+                    ex_dp, sim_dp = self.eval_design(ex_dp, self.database)  # evaluate the designs
+                else:
+                    sim_dp = self.eval_design(ex_dp, self.database)  # evaluate the designs
+                if config.cache_seen_designs:
+                    self.cached_SOC_sim[design_unique_code] = (ex_dp, sim_dp)
+            else:
+                ex_dp = self.cached_SOC_sim[cached_soc][0]
+                sim_dp = self.cached_SOC_sim[cached_soc][1]
 
         # collect the moves for debugging/visualization
         if config.DEBUG_MOVE:
@@ -2687,21 +2971,18 @@
 
         # visualization and verification
         if config.VIS_GR_PER_GEN:
+            print("@@ Visualizing generation...........")
             vis_hardware.vis_hardware(sim_dp.get_dp_rep())
         if config.RUN_VERIFICATION_PER_GEN or \
                 (config.RUN_VERIFICATION_PER_NEW_CONFIG and
-                 not(sim_dp.dp.get_hardware_graph().get_SOC_design_code() in self.seen_SOC_design_codes)):
+                 not(self.found_soc_design_code_in_cache(sim_dp.dp.get_hardware_graph().get_SOC_design_code(), self.seen_SOC_design_codes))):
             self.gen_verification_data(sim_dp, ex_dp)
         self.seen_SOC_design_codes.append(sim_dp.dp.get_hardware_graph().get_SOC_design_code())
 
 
         if not sim_dp.move_applied == None and config.print_info_regularly:
             sim_dp.move_applied.print_info()
-            print("design's latency: " + str(sim_dp.dp_stats.get_system_complex_metric("latency")))
-            print("design's power: " + str(sim_dp.dp_stats.get_system_complex_metric("power")))
-            print("design's area: " + str(sim_dp.dp_stats.get_system_complex_metric("area")))
-            print("design's sub area: " + str(sim_dp.dp_stats.get_system_complex_area_stacked_dram()))
-
+            sim_dp.dp_stats.print_summary()
 
         return (ex_dp, sim_dp), total_trans_cnt
 
@@ -2710,17 +2991,8 @@
         ctr = 0
         while True and ctr <100:
             ctr +=1
-            try:
-                des_tup_new, possible_des_cnt = self.gen_neigh_and_eval(des_tup)
-                return des_tup_new, possible_des_cnt
-                break
-            except SystemExit:
-                print("caught an exit")
-                continue
-            except Exception as e:
-                print("caught an exception")
-        print("return too many exception or exits")
-        exit(0)
+            des_tup_new, possible_des_cnt = self.gen_neigh_and_eval(des_tup)
+            return des_tup_new, possible_des_cnt
 
     # ------------------------------
     # Functionality:
@@ -2732,18 +3004,19 @@
     #       breadth: the breadth according to which to generate designs  (used for breadth wise search)
     #       depth: the depth according to which to generate designs (used for look ahead)
     # ------------------------------
-    def gen_some_neighs_and_eval(self, des_tup, breath_length, depth_length, des_tup_list):
+    def gen_some_neighs_and_eval(self, des_tup, breadth_length, depth_length, des_tup_list):
         # base case
         if depth_length == 0:
             return [des_tup]
         #des_tup_list = []
-        # iterate on breath
-        for i in range(0, breath_length):
+        # iterate on breadth
+        for i in range(0, breadth_length):
             self.SA_current_mini_breadth = 0
-            if not(breath_length == 1):
+            if not(breadth_length == 1):
                 self.SA_current_breadth += 1
                 self.SA_current_depth = -1
                 print("--------breadth--------")
+                self.reverted_last_itr = False
             # iterate on depth (generate one neighbour and evaluate it)
             self.SA_current_depth += 1
             #des_tup_new, possible_des_cnt = self.gen_neigh_and_eval(des_tup)
@@ -2755,7 +3028,7 @@
             des_tup_list.append(des_tup_new)
 
             # do more coverage if needed
-            """ 
+            """
             for i in range(0, max(possible_des_cnt,1)-1):
                 self.SA_current_mini_breadth += 1
                 des_tup_new_breadth, _ = self.gen_neigh_and_eval(des_tup)
@@ -2799,6 +3072,9 @@
         # generate some neighbouring design points and evaluate them
         des_tup_list =[]
         #config.SA_depth = 3*len(self.so_far_best_ex_dp.get_hardware_graph().get_blocks_by_type("mem"))+ len(self.so_far_best_ex_dp.get_hardware_graph().get_blocks_by_type("ic"))
+
+        self.reverted_last_itr = False
+        self.task_names_specialized_for = set() # hash to record all the task names for which we have used moves: split_swap or swap
         self.gen_some_neighs_and_eval((self.so_far_best_ex_dp, self.so_far_best_sim_dp), config.SA_breadth, config.SA_depth, des_tup_list)
         exploration_and_simulation_approximate_time_per_iteration = (time.time() - strt)/max(len(des_tup_list), 1)
         #print("sim time + neighbour generation per design point " + str((time.time() - strt)/max(len(des_tup_list), 1)))
@@ -2841,7 +3117,19 @@
     # ------------------------------
     def explore_one_design(self):
         self.so_far_best_ex_dp = self.init_ex_dp
-        self.init_sim_dp = self.so_far_best_sim_dp = self.eval_design(self.so_far_best_ex_dp, self.database)
+        #self.init_sim_dp = self.eval_design(self.so_far_best_ex_dp, self.database)
+        if config.DYN_SCHEDULING_INSTEAD_OF_MAPPING:
+            self.init_ex_dp, self.init_sim_dp = self.so_far_best_ex_dp, self.so_far_best_sim_dp = self.eval_design(self.so_far_best_ex_dp, self.database)
+        else:
+            self.init_sim_dp = self.so_far_best_sim_dp = self.eval_design(self.so_far_best_ex_dp, self.database)
+        
+        for b in self.so_far_best_sim_dp.dp_rep.get_hardware_graph().blocks:
+            if b.type == "mem":
+                start_bytes = b.area_in_bytes_list[0]
+                end_bytes = b.area_in_bytes_list[-1]
+                assert np.isclose(start_bytes, 0.) and np.isclose(end_bytes, 0.), f"** blk {b.instance_name} start bytes: {start_bytes}, end bytes: {end_bytes} not equal to 0!"
+                
+        self.init_sim_dp.dp_stats.print_summary(prefix="Init ")
         this_itr_ex_sim_dp_dict = {}
         this_itr_ex_sim_dp_dict[self.so_far_best_ex_dp] = self.so_far_best_sim_dp
         #self.init_sim_dp = self.eval_design(self.so_far_best_ex_dp, self.database)
@@ -2905,7 +3193,7 @@
                 move_validity = ma.is_valid()
                 ref_des_dist_to_goal_all = ma.get_logs("ref_des_dist_to_goal_all")
                 ref_des_dist_to_goal_non_cost = ma.get_logs("ref_des_dist_to_goal_non_cost")
-                #neighbouring_design_space_size = self.convert_dictionary_to_parsable_csv_with_semi_column(ma.get_design_space_size())
+                # neighbouring_design_space_size = self.convert_dictionary_to_parsable_csv_with_semi_column(ma.get_design_space_size())
                 neighbouring_design_space_size = sim_dp.get_neighbouring_design_space_size()
                 workload = ma.get_logs("workload")
             else:  # happens at the very fist iteration
@@ -2941,6 +3229,7 @@
             block_area_break_down = self.convert_dictionary_to_parsable_csv_with_underline(sim_dp.dp_stats.SOC_area_dict)
             routing_complexity = sim_dp.dp_rep.get_hardware_graph().get_routing_complexity()
             area_non_dram = sim_dp.dp_stats.get_system_complex_area_stacked_dram()["non_dram"]
+            area_pe = sim_dp.dp_stats.get_system_complex_area_stacked_dram()["pe"]
             area_dram = sim_dp.dp_stats.get_system_complex_area_stacked_dram()["dram"]
             simple_topology = sim_dp.dp_rep.get_hardware_graph().get_simplified_topology_code()
             channel_cnt = sim_dp.dp_rep.get_hardware_graph().get_number_of_channels()
@@ -2974,16 +3263,17 @@
                     "transformation selection time" : transformation_selection_time,
                 "design duplication time": pickling_time,
                 "neighbour selection time": self.neighbour_selection_time,
-                "dist_to_goal_all" : sim_dp.dp_stats.dist_to_goal(metrics_to_look_into=["area", "latency", "power", "cost"],
+                "dist_to_goal_all" : sim_dp.dp_stats.dist_to_goal(metrics_to_look_into=config.budgetted_metrics,
                                                                   mode="eliminate"),
-                    "dist_to_goal_non_cost" : sim_dp.dp_stats.dist_to_goal(metrics_to_look_into=["area", "latency", "power"],
+                    "dist_to_goal_non_cost" : sim_dp.dp_stats.dist_to_goal(metrics_to_look_into=[metric for metric in config.budgetted_metrics if metric != "cost"],
                                                                            mode="eliminate"),
                     "ref_des_dist_to_goal_all" : ref_des_dist_to_goal_all,
                     "ref_des_dist_to_goal_non_cost" : ref_des_dist_to_goal_non_cost,
-                    "best_des_so_far_dist_to_goal_non_cost": self.so_far_best_sim_dp.dp_stats.dist_to_goal(metrics_to_look_into=["area", "latency", "power"],
+                    "best_des_so_far_dist_to_goal_non_cost": self.so_far_best_sim_dp.dp_stats.dist_to_goal(metrics_to_look_into=[metric for metric in config.budgetted_metrics if metric != "cost"],
                                                                            mode="eliminate"),
-                    "best_des_so_far_dist_to_goal_all": self.so_far_best_sim_dp.dp_stats.dist_to_goal(metrics_to_look_into=["area", "latency", "power"],
+                    "best_des_so_far_dist_to_goal_all": self.so_far_best_sim_dp.dp_stats.dist_to_goal(metrics_to_look_into=[metric for metric in config.budgetted_metrics if metric != "cost"],
                                                                            mode="eliminate"),
+                    "best_des_so_far_area_pe": self.so_far_best_sim_dp.dp_stats.get_system_complex_area_stacked_dram()["pe"],
                     "best_des_so_far_area_non_dram": self.so_far_best_sim_dp.dp_stats.get_system_complex_area_stacked_dram()["non_dram"],
                     "best_des_so_far_area_dram": self.so_far_best_sim_dp.dp_stats.get_system_complex_area_stacked_dram()["dram"],
                     #"area_breakdown_subtype":self.convert_dictionary_to_parsable_csv_with_semi_column(sim_dp.dp_stats.SOC_area_subtype_dict.keys()),
@@ -3013,6 +3303,7 @@
                     "sub_block_area_break_down":sub_block_area_break_down,
                 "task_cnt": task_cnt,
                 "channel_cnt":channel_cnt,
+                "area_pe":area_pe,
                 "area_dram":area_dram,
                 "area_non_dram":area_non_dram
             }
@@ -3116,7 +3407,7 @@
                 greedy_ctr_run += 1
         elif moos_greedy_mode == "phv":
             phv_improvement = True
-            hyper_volume_ref = [300, 2, 2]
+            hyper_volume_ref = [300, 100, 2]
             local_pareto = {}
             phv_so_far = 0
             while phv_improvement and greedy_ctr_run < config.MOOS_GREEDY_CTR_RUN:
@@ -3266,9 +3557,10 @@
         self.so_far_best_ex_dp = self.init_ex_dp
         self.so_far_best_sim_dp = self.eval_design(self.so_far_best_ex_dp, self.database)
         self.init_sim_dp = self.eval_design(self.so_far_best_ex_dp, self.database)
+        self.init_sim_dp.dp_stats.print_summary(prefix="Init ")
 
         # visualize/checkpoint/PA generation
-        vis_hardware.vis_hardware(self.so_far_best_sim_dp.get_dp_rep())
+        # vis_hardware.vis_hardware(self.so_far_best_sim_dp.get_dp_rep())
         if config.RUN_VERIFICATION_PER_GEN or config.RUN_VERIFICATION_PER_IMPROVMENT or config.RUN_VERIFICATION_PER_NEW_CONFIG:
             self.gen_verification_data(self.so_far_best_sim_dp, self.so_far_best_ex_dp)
 
@@ -3276,8 +3568,8 @@
         #num_of_workloads = len(self.so_far_best_sim_dp.dp_stats.database.get_workloads_last_task().values())
         # initializing the tree
         self.pareto_global = {}
-        self.pareto_global [self.so_far_best_ex_dp] = self.so_far_best_sim_dp
-        hyper_volume_ref = [300,2,2]
+        self.pareto_global[self.so_far_best_ex_dp] = self.so_far_best_sim_dp
+        hyper_volume_ref = [300,100,2]
 
         pareto_global_child_evaluation = self.evaluate_pareto(self.pareto_global, hyper_volume_ref)
         root_node = self.moos_tree.get_root()
@@ -3347,6 +3639,8 @@
 
                 # get new pareto design and merge, and evaluate (update the tree)
                 self.log_data(this_itr_ex_sim_dp_dict)
+                print("-------:):):):):)----------")
+                self.cur_best_sim_dp.dp_stats.print_summary(prefix="Best ")
                 self.collect_stats(this_itr_ex_sim_dp_dict)
                 pareto_designs = self.get_pareto_designs(this_itr_ex_sim_dp_dict)
                 pareto_global_child.update(pareto_designs)
@@ -3385,7 +3679,7 @@
                 self.so_far_best_sim_dp  = self.cur_best_sim_dp
 
                 print("reason to terminate is:" + reason_to_terminate)
-                vis_hardware.vis_hardware(self.cur_best_sim_dp.get_dp_rep())
+                vis_hardware.vis_hardware(self.cur_best_sim_dp.get_dp_rep(), output_folder=self.viz_dir, output_file_name="system_image_best.pdf")
                 if not (self.last_des_trail == None):
                     if self.last_des_trail == None:
                         self.last_des_trail = (
@@ -3405,7 +3699,7 @@
 
             print(" >>>>> des" + " latency:" + str(self.so_far_best_sim_dp.dp_stats.get_system_complex_metric("latency")))
 
-            """ 
+            """
             stat_result = self.so_far_best_sim_dp.dp_stats
             if stat_result.fits_budget(1):
                 should_terminate = True
@@ -3430,11 +3724,15 @@
     # ------------------------------
     def explore_ds(self):
         self.so_far_best_ex_dp = self.init_ex_dp
-        self.so_far_best_sim_dp = self.eval_design(self.so_far_best_ex_dp, self.database)
-        self.init_sim_dp = self.eval_design(self.so_far_best_ex_dp, self.database)
+        if config.DYN_SCHEDULING_INSTEAD_OF_MAPPING:
+            self.so_far_best_ex_dp, self.init_sim_dp = self.eval_design(self.so_far_best_ex_dp, self.database)
+        else:
+            self.init_sim_dp = self.eval_design(self.so_far_best_ex_dp, self.database)
+        self.so_far_best_sim_dp = self.init_sim_dp
+        self.init_sim_dp.dp_stats.print_summary(prefix="Init ")
 
         # visualize/checkpoint/PA generation
-        vis_hardware.vis_hardware(self.so_far_best_sim_dp.get_dp_rep())
+        # vis_hardware.vis_hardware(self.so_far_best_sim_dp.get_dp_rep())
         if config.RUN_VERIFICATION_PER_GEN or config.RUN_VERIFICATION_PER_IMPROVMENT or config.RUN_VERIFICATION_PER_NEW_CONFIG:
             self.gen_verification_data(self.so_far_best_sim_dp, self.so_far_best_ex_dp)
 
@@ -3443,7 +3741,11 @@
         cur_temp = config.annealing_max_temp
 
         while True:
-            this_itr_ex_sim_dp_dict = self.simple_SA()   # run simple simulated annealing
+            # define the result dictionary
+            this_itr_ex_sim_dp_dict:Dict[ExDesignPoint: SimDesignPoint] = {}
+            this_itr_ex_sim_dp_dict[self.so_far_best_ex_dp] = self.so_far_best_sim_dp  # init the res dict
+            if not config.SINGLE_RUN:
+                this_itr_ex_sim_dp_dict = self.simple_SA()   # run simple simulated annealing
             self.total_iteration_ctr += len(list(this_itr_ex_sim_dp_dict.keys()))
 
             # collect profiling information about moves and designs generated
@@ -3459,9 +3761,7 @@
             self.neighbour_selection_time = t2-t1
             self.log_data(this_itr_ex_sim_dp_dict)
             print("-------:):):):):)----------")
-            print("Best design's latency: " + str(self.cur_best_sim_dp.dp_stats.get_system_complex_metric("latency")))
-            print("Best design's power: " + str(self.cur_best_sim_dp.dp_stats.get_system_complex_metric("power")))
-            print("Best design's sub area: " + str(self.cur_best_sim_dp.dp_stats.get_system_complex_area_stacked_dram()))
+            self.cur_best_sim_dp.dp_stats.print_summary(prefix="Best ")
 
             if  not self.cur_best_sim_dp.move_applied == None:
                 self.cur_best_sim_dp.move_applied.print_info()
@@ -3482,8 +3782,11 @@
                 should_terminate, reason_to_terminate = self.update_ctrs()
 
             if should_terminate:
+                self.reason_to_terminate = reason_to_terminate
                 print("reason to terminate is:" + reason_to_terminate)
-                vis_hardware.vis_hardware(self.cur_best_sim_dp.get_dp_rep())
+                if reason_to_terminate == "exploration timed out":
+                    break
+                vis_hardware.vis_hardware(self.cur_best_sim_dp.get_dp_rep(), output_folder=self.viz_dir, output_file_name="system_image_best.pdf")
                 if not (self.last_des_trail == None):
                     if self.last_des_trail == None:
                         self.last_des_trail = (copy.deepcopy(self.so_far_best_sim_dp), copy.deepcopy(self.so_far_best_sim_dp))
@@ -3496,7 +3799,6 @@
                 if config.VIS_MOVE_TRAIL:
                     plot.des_trail_plot(self.des_trail_list, self.move_profile, des_per_iteration)
                     plot.move_profile_plot(self.move_profile)
-                self.reason_to_terminate = reason_to_terminate
                 return
             cur_temp -= config.annealing_temp_dec
             self.vis_move_trail_ctr += 1
@@ -3523,7 +3825,7 @@
     # Variables:
     #      explorations_start_time: to exploration start time used to determine the end-to-end exploration time.
     # -----------------------------
-    def report(self, exploration_start_time):
+    def report(self, exploration_start_time, result_folder_mod):
         exploration_end_time = time.time()
         total_sim_time = exploration_end_time - exploration_start_time
         print("*********************************")
@@ -3546,7 +3848,7 @@
         print("The design meet the latency requirement: " + str(self.so_far_best_sim_dp.dp_stats.get_system_complex_metric("latency") < config.objective_budget))
         vis_hardware.vis_hardware(self.so_far_best_ex_dp)
         if config.VIS_FINAL_RES:
-            vis_hardware.vis_hardware(self.so_far_best_ex_dp, config.hw_graphing_mode)
+            vis_hardware.vis_hardware(self.so_far_best_ex_dp, config.hw_graphing_mode, output_folder=result_folder_mod)
 
         # write the output
         home_dir = os.getcwd()
@@ -3641,10 +3943,13 @@
         tsks_left_to_optimize = list(set(tasks_not_meeting_budget) - set(self.krnels_not_to_consider))
 
         if stat_result.fits_budget(1) :
-            config.VIS_GR_PER_GEN = True  # visualize the graph per design point generation
-            config.VIS_SIM_PER_GEN = True  # if true, we visualize the simulation progression
+            # config.VIS_GR_PER_GEN = True  # visualize the graph per design point generation
+            # config.VIS_SIM_PER_GEN = True  # if true, we visualize the simulation progression
             self.fitted_budget_ctr +=1
-        if (self.fitted_budget_ctr > config.fitted_budget_ctr_threshold):
+        if config.EXPLR_TIMEOUT is not None and (time.time() - self.FARSI_start_time) > config.EXPLR_TIMEOUT:
+            reason_to_terminate = "exploration timed out"
+            should_terminate = True
+        elif (self.fitted_budget_ctr > config.fitted_budget_ctr_threshold):
             reason_to_terminate = "met the budget"
             should_terminate = True
         elif self.des_stag_ctr > self.DES_STAG_THRESHOLD:
@@ -3668,6 +3973,7 @@
             else:
                 reason_to_terminate = "exploration (total itr_ctr) iteration threshold reached"
             should_terminate = True
+        assert config.SINGLE_RUN == 0, "shouldn't have come here for single run"
 
         self.counters.update(self.krnel_rnk_to_consider, self.krnel_stagnation_ctr, self.fitted_budget_ctr, self.des_stag_ctr,
                              self.krnels_not_to_consider, self.population_generation_cnt, self.found_any_improvement, self.total_iteration_ctr)
@@ -3675,6 +3981,82 @@
         print(">>>>> total iteration count is: " + str(self.total_iteration_ctr))
         return should_terminate, reason_to_terminate
 
+class HillClimbing_FARSI(HillClimbing):
+    def get_kernels_s_contribution(self, selected_metric, sim_dp):
+        krnl_prob_dict = {}  # (kernel, metric_value)
+
+        #krnls = sim_dp.get_dp_stats().get_kernels()
+        # filter it kernels whose workload meet the budget
+        krnls = self.filter_in_kernels_meeting_budget(selected_metric, sim_dp)
+        if krnls == []: # the design meets the budget, hence all kernels can be improved for cost improvement
+            krnls = sim_dp.get_dp_stats().get_kernels()
+            # remove dummy tasks
+            new_krnls = []
+            for krnl in krnls:
+                if not krnl.get_task().is_task_dummy():
+                    new_krnls.append(krnl)
+            krnls = new_krnls
+
+        metric_total = sum([krnl.stats.get_metric(selected_metric) for krnl in krnls])
+        if config.RT_AWARE_TASK_SEL and selected_metric == "latency":
+            # sort kernels based on their contribution to the metric of interest
+            for krnl in krnls:
+                # for each kernel, compute lat*slack = lat*(service_time)
+                krnl_lat = krnl.stats.get_metric("latency")
+                krnl_prob_raw = -round(krnl_lat*(krnl.deadline - (krnl.completion_time - krnl.arrival_time)),9)
+                try:
+                    krnl_prob_dict[krnl] = math.exp(krnl_prob_raw)
+                except:
+                    krnl_prob_dict[krnl] = math.inf
+        else:
+            # sort kernels based on their contribution to the metric of interest
+            for krnl in krnls:
+                krnl_prob_dict[krnl] = round(krnl.stats.get_metric(selected_metric)/metric_total,9)
+
+        if not "bottleneck" in self.move_s_krnel_selection:
+            for krnl in krnls:
+                krnl_prob_dict[krnl] = 1
+        return krnl_prob_dict
+    
+    def select_kernel(self, ex_dp, sim_dp, selected_metric, move_sorted_metric_dir):
+
+        # get each kernel's contributions
+        krnl_contribution_dict = self.get_kernels_s_contribution(selected_metric, sim_dp)
+        # get each kernel's improvement cost
+        krnl_improvement_ease = self.get_kernels_s_improvement_ease(ex_dp, sim_dp, selected_metric, move_sorted_metric_dir)
+
+        # combine the selections methods
+        # multiply the probabilities for a more complex metric
+        krnl_prob_dict = {}
+        for krnl in krnl_contribution_dict.keys():
+            krnl_prob_dict[krnl] = krnl_contribution_dict[krnl] * krnl_improvement_ease[krnl]
+
+        # give zero probablity to the krnls that you filtered out
+        for krnl in sim_dp.get_dp_stats().get_kernels():
+            if krnl not in krnl_prob_dict.keys():
+                krnl_prob_dict[krnl] = 0
+        # sort
+        #krnl_prob_dict_sorted = {k: v for k, v in sorted(krnl_prob_dict.items(), key=lambda item: item[1])}
+        krnl_prob_dict_sorted = sorted(krnl_prob_dict.items(), key=lambda item: item[1], reverse=True)
+
+        # get the worse kernel
+        if config.move_krnel_ranking_mode == "exact":  # for area to allow us pick scenarios that are not necessarily the worst
+            #selected_krnl = list(krnl_prob_dict_sorted.keys())[
+            #    len(krnl_prob_dict_sorted.keys()) - 1 - self.krnel_rnk_to_consider]
+            for krnl, prob in krnl_prob_dict_sorted:
+                if krnl.get_task_name() in self.krnels_not_to_consider:
+                    continue
+                selected_krnl = krnl
+                break
+        else:
+            selected_krnl = self.pick_from_prob_dict(krnl_prob_dict_sorted)
+
+        if config.transformation_selection_mode == "random":
+            krnls = sim_dp.get_dp_stats().get_kernels()
+            random.seed(datetime.now().microsecond)
+            selected_krnl = random.choice(krnls)
+
+        return selected_krnl, krnl_prob_dict, krnl_prob_dict_sorted
 
 class moosTreeNode:
     def __init__(self, k_intervals):
@@ -3858,13 +4240,3 @@
         """
         return best_node
 
-
-
-
-
-
-
-
-
-
-
