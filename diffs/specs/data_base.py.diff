--- ./Project_FARSI_orig/specs/data_base.py
+++ ./Project_FARSI/specs/data_base.py
@@ -8,6 +8,10 @@
 from operator import itemgetter, attrgetter
 from settings import config
 from datetime import datetime
+from abc import ABC, abstractmethod
+from typing import List, Dict
+
+from specs.database_input import database_input_class
 #from specs import database_input
 if config.simulation_method == "power_knobs":
     from specs import database_input_powerKnobs as database_input
@@ -53,11 +57,12 @@
 # this class handles the input data base data.
 # any class that wants to read the database data needs to talk to this class
 class DataBase:
-    def __init__(self, db_input, hw_sampling):
-        self.cached_blockL_to_block = {}
-        self.cached_block_to_blockL = {}
+    def __init__(self, db_input:database_input_class, hw_sampling):
+        self.cached_blockL_to_block:Dict[BlockL, Block] = {}
+        self.cached_block_to_blockL:Dict[Block, BlockL] = {}
+
         self.db_input = db_input
-        self.tasksL = self.db_input.tasksL   # task
+        self.tasksL:List[TaskL] = self.db_input.tasksL   # task
         self.pe_mapsL = self.db_input.pe_mapsL  # pe maps
         self.blocksL = self.db_input.blocksL  # blocks
         self.pe_schedulesL = db_input.pe_schedeulesL  # schedules
@@ -65,6 +70,12 @@
         self.SOCsL = db_input.SOCsL  # SOC
         self.SOC_id = 0  # soc id.
         self.hw_sampling = hw_sampling   # how to sample hardware
+        self.task_to_mappable_pe_map = db_input.task_to_mappable_pe_wr_map
+        for k in self.task_to_mappable_pe_map.keys():
+            self.task_to_mappable_pe_map[k] = [pe_name_wr_tup[0] for pe_name_wr_tup in self.task_to_mappable_pe_map[k]]
+
+        self.task_is_accelrable_map = db_input.task_is_accelrable_map
+        self.pe_to_mappable_task_map = db_input.pe_to_mappable_task_map
 
         # cluster blocks
         self.ic_block_list = self.get_blocksL_by_type(block_type="ic")  # list of ICs
@@ -107,7 +118,7 @@
                          self.get_block_leakage_power(obj),
                          self.get_block_power_knobs(obj),)
         elif len(argv) == 0 and isinstance(obj, TaskL):
-            return Task(obj.task_name, self.get_task_work(obj), self.get_task_iteration(obj), self.get_task_type(obj), self.get_task_throughput_info(obj))
+            return Task(name=obj.task_name, dag_id=obj.dag_id, parent_graph_arr_time=obj.parent_graph_arr_time, sr= obj.sr, sdr=obj.sdr, work=self.get_task_work(obj), iteration_ctr=self.get_task_iteration(obj), type=self.get_task_type(obj), throughput_info=self.get_task_throughput_info(obj))
         elif len(argv) == 3 and isinstance(obj, Task) and isinstance(argv[0], Block):
             raise Exception("this is case is deprecated")
             task = obj
@@ -169,7 +180,7 @@
         for SOCL in self.SOCsL:
             if SOCL.type == type:
                 if not metric in SOCL.get_budgetted_metric_names():
-                    print("this metric is not budgget")
+                    print(f"Metric {metric} is not budgetted")
                     exit(0)
                 return SOCL.get_budget(metric)
 
@@ -178,7 +189,7 @@
         for SOCL in self.SOCsL:
             if SOCL.type == type:
                 if not metric in SOCL.get_other_metrics_names():
-                    print("this metric is not included in the other metrics")
+                    print(f"Metric {metric} is not included in other metrics")
                     exit(0)
                 return SOCL.get_other_metrics_ideal_value(metric)
 
@@ -191,13 +202,18 @@
                     return SOCL.set_other_metrics_ideal_values(metric, value)
 
     # get the desired (basically budget) value for various metrics
-    def get_ideal_metric_value(self, metric, type):
+    def get_ideal_metric_value(self, metric, type_):
+        val = None
         for SOCL in self.SOCsL:
-            if SOCL.type == type:
+            if SOCL.type == type_:
                 if metric in SOCL.get_budgetted_metric_names():
-                    return SOCL.get_budget(metric)
+                    val = SOCL.get_budget(metric)
+                    break
                 elif metric in SOCL.get_other_metric_names():
-                    return SOCL.get_other_metrics_ideal_values(metric)
+                    val = SOCL.get_other_metrics_ideal_values(metric)
+                    break
+        assert val != None, "Something went wrong in get_ideal_metric_value()"
+        return val
 
     # ------------------------------
     # Functionality:
@@ -335,7 +351,11 @@
     #       parses taskL and generates Tasks objects (including their dependencies)
     # -------------------------------------------
     def parse_and_gen_tasks(self):
-        tasks = [self.cast(taskL) for taskL in self.tasksL]
+        tasks:List[Task] = []
+        for taskL in self.tasksL:
+            tasks.append(self.cast(taskL))
+            # self.task_name_to_task_obj_map[tasks[-1].name] = tasks[-1]
+            
         for task in tasks:
             corresponding_taskL = self.get_taskL_from_task_name(task.name)
             if config.eval_mode == "statistical":
@@ -405,10 +425,18 @@
         suffix = blk_name.split("_")[-1]
         # This is becuase BlockL do not have an instance name
         # generate the block
-        blockL = [el for el in self.blocksL if el.block_instance_name_without_type == blk_name_refined][0]
+        blocksL = []
+        for el in self.blocksL:
+            if el.block_instance_name_without_type == blk_name_refined:
+                blocksL.append(el)
+        try:
+            blockL = blocksL[0]
+        except:
+            print(f"Issue with block: {blk_name_refined} parsed from hardware graph file not present in IP library: {[n.block_instance_name_without_type for n in self.blocksL]}")
+            exit(1)
         block = self.cast(blockL)
-        block_name = block.instance_name + "_" + suffix
-        block.set_instance_name(block_name)
+        block_name = block.instance_name
+        # block.set_instance_name(block_name)
         # set the SOC type:
         # TODO: for now we just set it to the most superior SOC. Later, get an input for this
         ordered_SOCsL = sorted(self.SOCsL, key=lambda SOC: SOC.get_budget("latency"))
@@ -710,7 +738,8 @@
             metric_to_sort = 'peak_work_rate'
         elif metric == "power":
             #metric_to_sort = 'work_over_energy'
-            metric_to_sort = 'one_over_power'
+            # metric_to_sort = 'one_over_power'
+            metric_to_sort = 'one_over_total_power'
         elif metric == "area":
             metric_to_sort = 'one_over_area'
         else:
@@ -755,7 +784,8 @@
             metric_to_sort = 'peak_work_rate'
         elif metric == "power":
             #metric_to_sort = 'work_over_energy'
-            metric_to_sort = 'one_over_power'
+            # metric_to_sort = 'one_over_power'
+            metric_to_sort = 'one_over_total_power'
         elif metric == "area":
             metric_to_sort = 'one_over_area'
         else:
@@ -789,7 +819,44 @@
             metric_to_sort = 'peak_work_rate'
         elif metric == "power":
             # metric_to_sort = 'work_over_energy'
-            metric_to_sort = 'one_over_power'
+            # metric_to_sort = 'one_over_power'
+            metric_to_sort = 'one_over_total_power'
+        elif metric == "area":
+            metric_to_sort = 'one_over_area'
+        else:
+            print("metric: " + metric + " is not defined")
+
+        if sampling_dir > 0:
+            reversed = True
+        else:
+            reversed = False
+        srtd_comptble_blcks = sorted(all_compatible_blocks, key=attrgetter(metric_to_sort), reverse=reversed)  #
+        idx = 0
+
+        # find the block
+        results = []
+        for blck in srtd_comptble_blcks:
+            if sampling_dir < 0:  # need to reduce
+                if (getattr(blck, metric_to_sort) >= getattr(blck_to_imprv, metric_to_sort)):
+                    results.append(blck)
+            elif sampling_dir > 0:  # need to reduce
+                if (getattr(blck, metric_to_sort) <= getattr(blck_to_imprv, metric_to_sort)):
+                    results.append(blck)
+
+        return results
+
+    @abstractmethod
+    def up_sample_down_sample_block_multi_metric_fast(self, blck_to_imprv, sorted_metric_dir, move=None, selected_kernel=None, tasks=[]):
+        pass
+
+    def equal_sample_up_sample_down_sample_block_fast(self, blck_to_imprv, metric, sampling_dir, tasks=[]):
+        all_compatible_blocks = self.find_all_compatible_blocks_fast(blck_to_imprv.type, tasks)
+        if metric == "latency":
+            metric_to_sort = 'peak_work_rate'
+        elif metric == "power":
+            #metric_to_sort = 'work_over_energy'
+            # metric_to_sort = 'one_over_power'
+            metric_to_sort = 'one_over_total_power'
         elif metric == "area":
             metric_to_sort = 'one_over_area'
         else:
@@ -799,12 +866,15 @@
             reversed = True
         else:
             reversed = False
+
         srtd_comptble_blcks = sorted(all_compatible_blocks, key=attrgetter(metric_to_sort), reverse=reversed)  #
+        #srtd_comptble_blcks = sorted(all_compatible_blocks, key=lambda blk: (getattr(blk, metrics_to_sort[0]), getattr(blk, metrics_to_sort[1]), getattr(blk, metrics_to_sort[2])), reverse=reversed)  #
         idx = 0
 
         # find the block
         results = []
         for blck in srtd_comptble_blcks:
+            #if (getattr(blck, metric_to_sort) == getattr(blck_to_imprv, metric_to_sort)):
             if sampling_dir < 0:  # need to reduce
                 if (getattr(blck, metric_to_sort) >= getattr(blck_to_imprv, metric_to_sort)):
                     results.append(blck)
@@ -814,7 +884,9 @@
 
         return results
 
-    def up_sample_down_sample_block_multi_metric_fast(self, blck_to_imprv, sorted_metric_dir, tasks=[]):
+class DataBase_FARSI(DataBase):
+    
+    def up_sample_down_sample_block_multi_metric_fast(self, blck_to_imprv, sorted_metric_dir, move=None, selected_kernel=None, tasks=[]):
         all_compatible_blocks = self.find_all_compatible_blocks_fast(blck_to_imprv.type, tasks)
 
         metrics_to_sort_reversed = []
@@ -823,7 +895,7 @@
                 metric_to_sort = 'peak_work_rate'
             elif metric == "power":
                 #metric_to_sort = 'work_over_energy'
-                metric_to_sort = 'one_over_power'
+                metric_to_sort = 'one_over_total_power'
             elif metric == "area":
                 metric_to_sort = 'one_over_area'
             else:
@@ -889,37 +961,3 @@
         #    results = [srtd_comptble_blcks[-1]]
 
         return results
-
-    def equal_sample_up_sample_down_sample_block_fast(self, blck_to_imprv, metric, sampling_dir, tasks=[]):
-        all_compatible_blocks = self.find_all_compatible_blocks_fast(blck_to_imprv.type, tasks)
-        if metric == "latency":
-            metric_to_sort = 'peak_work_rate'
-        elif metric == "power":
-            #metric_to_sort = 'work_over_energy'
-            metric_to_sort = 'one_over_power'
-        elif metric == "area":
-            metric_to_sort = 'one_over_area'
-        else:
-            print("metric: " + metric + " is not defined")
-
-        if sampling_dir > 0:
-            reversed = True
-        else:
-            reversed = False
-
-        srtd_comptble_blcks = sorted(all_compatible_blocks, key=attrgetter(metric_to_sort), reverse=reversed)  #
-        #srtd_comptble_blcks = sorted(all_compatible_blocks, key=lambda blk: (getattr(blk, metrics_to_sort[0]), getattr(blk, metrics_to_sort[1]), getattr(blk, metrics_to_sort[2])), reverse=reversed)  #
-        idx = 0
-
-        # find the block
-        results = []
-        for blck in srtd_comptble_blcks:
-            #if (getattr(blck, metric_to_sort) == getattr(blck_to_imprv, metric_to_sort)):
-            if sampling_dir < 0:  # need to reduce
-                if (getattr(blck, metric_to_sort) >= getattr(blck_to_imprv, metric_to_sort)):
-                    results.append(blck)
-            elif sampling_dir > 0:  # need to reduce
-                if (getattr(blck, metric_to_sort) <= getattr(blck_to_imprv, metric_to_sort)):
-                    results.append(blck)
-
-        return results
